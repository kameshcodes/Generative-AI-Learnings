{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgiDx0hH70Mo8Opc2h1mJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameshcodes/Generative-AI-Learnings/blob/main/RAGs_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. $\\text{Data Ingestion Pipeline Implementation}$\n",
        "\n",
        " The first step of the data ingestion pipeline is $\\text{extracting and spliting text}$ from the pdf documents"
      ],
      "metadata": {
        "id": "CeS1b2h3GVAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Installation"
      ],
      "metadata": {
        "id": "GiRaAjY0O7Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install llama-index langchain PyPDF2 pdfminer.six -q\n",
        "! pip install -U langchain-community -q"
      ],
      "metadata": {
        "id": "0rqmk-gqHJ_O"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load Pdf and Extract Text from it"
      ],
      "metadata": {
        "id": "QlX_HsiHO_45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "PATH = \"/content/paper-1.pdf\"\n",
        "\n",
        "\n",
        "reader = PdfReader(PATH)\n",
        "\n",
        "pages = reader.pages"
      ],
      "metadata": {
        "id": "jjS5uE9DHmLu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj89MADGLZCD",
        "outputId": "ea22b7c1-329c-4a13-df65-aa917099b138"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PyPDF2._page._VirtualList at 0x7b890aa75de0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkIhnO7oLYz7",
        "outputId": "55dcaecf-3d42-4e8c-84ee-7bcf034b5bff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/Annots': [IndirectObject(270, 0, 135828519482704),\n",
              "  IndirectObject(307, 0, 135828519482704),\n",
              "  IndirectObject(271, 0, 135828519482704),\n",
              "  IndirectObject(272, 0, 135828519482704),\n",
              "  IndirectObject(308, 0, 135828519482704),\n",
              "  IndirectObject(273, 0, 135828519482704),\n",
              "  IndirectObject(274, 0, 135828519482704),\n",
              "  IndirectObject(275, 0, 135828519482704),\n",
              "  IndirectObject(276, 0, 135828519482704),\n",
              "  IndirectObject(309, 0, 135828519482704),\n",
              "  IndirectObject(277, 0, 135828519482704),\n",
              "  IndirectObject(278, 0, 135828519482704),\n",
              "  IndirectObject(279, 0, 135828519482704),\n",
              "  IndirectObject(280, 0, 135828519482704),\n",
              "  IndirectObject(281, 0, 135828519482704),\n",
              "  IndirectObject(282, 0, 135828519482704),\n",
              "  IndirectObject(284, 0, 135828519482704),\n",
              "  IndirectObject(310, 0, 135828519482704),\n",
              "  IndirectObject(283, 0, 135828519482704)],\n",
              " '/Contents': {'/Filter': '/FlateDecode'},\n",
              " '/MediaBox': [0, 0, 595.276, 841.89],\n",
              " '/Parent': {'/Count': 6,\n",
              "  '/Kids': [IndirectObject(129, 0, 135828519482704),\n",
              "   IndirectObject(1, 0, 135828519482704),\n",
              "   IndirectObject(3, 0, 135828519482704),\n",
              "   IndirectObject(11, 0, 135828519482704),\n",
              "   IndirectObject(13, 0, 135828519482704),\n",
              "   IndirectObject(15, 0, 135828519482704)],\n",
              "  '/Parent': {'/Count': 10,\n",
              "   '/Kids': [IndirectObject(168, 0, 135828519482704),\n",
              "    IndirectObject(175, 0, 135828519482704)],\n",
              "   '/Type': '/Pages'},\n",
              "  '/Type': '/Pages'},\n",
              " '/Resources': {'/Font': {'/F116': {'/BaseFont': '/GDFGMZ+NimbusRomNo9L-Medi',\n",
              "    '/Encoding': {'/Differences': [2,\n",
              "      '/fi',\n",
              "      34,\n",
              "      '/quotedbl',\n",
              "      37,\n",
              "      '/percent',\n",
              "      39,\n",
              "      '/quoteright',\n",
              "      '/parenleft',\n",
              "      '/parenright',\n",
              "      43,\n",
              "      '/plus',\n",
              "      '/comma',\n",
              "      '/hyphen',\n",
              "      '/period',\n",
              "      48,\n",
              "      '/zero',\n",
              "      '/one',\n",
              "      '/two',\n",
              "      '/three',\n",
              "      '/four',\n",
              "      '/five',\n",
              "      '/six',\n",
              "      '/seven',\n",
              "      '/eight',\n",
              "      '/nine',\n",
              "      '/colon',\n",
              "      '/semicolon',\n",
              "      63,\n",
              "      '/question',\n",
              "      65,\n",
              "      '/A',\n",
              "      '/B',\n",
              "      '/C',\n",
              "      '/D',\n",
              "      '/E',\n",
              "      '/F',\n",
              "      '/G',\n",
              "      '/H',\n",
              "      '/I',\n",
              "      '/J',\n",
              "      '/K',\n",
              "      '/L',\n",
              "      '/M',\n",
              "      '/N',\n",
              "      '/O',\n",
              "      '/P',\n",
              "      '/Q',\n",
              "      '/R',\n",
              "      '/S',\n",
              "      '/T',\n",
              "      '/U',\n",
              "      '/V',\n",
              "      '/W',\n",
              "      '/X',\n",
              "      '/Y',\n",
              "      '/Z',\n",
              "      '/bracketleft',\n",
              "      93,\n",
              "      '/bracketright',\n",
              "      96,\n",
              "      '/quoteleft',\n",
              "      '/a',\n",
              "      '/b',\n",
              "      '/c',\n",
              "      '/d',\n",
              "      '/e',\n",
              "      '/f',\n",
              "      '/g',\n",
              "      '/h',\n",
              "      '/i',\n",
              "      '/j',\n",
              "      '/k',\n",
              "      '/l',\n",
              "      '/m',\n",
              "      '/n',\n",
              "      '/o',\n",
              "      '/p',\n",
              "      '/q',\n",
              "      '/r',\n",
              "      '/s',\n",
              "      '/t',\n",
              "      '/u',\n",
              "      '/v',\n",
              "      '/w',\n",
              "      '/x',\n",
              "      '/y',\n",
              "      '/z',\n",
              "      147,\n",
              "      '/quotedblleft',\n",
              "      '/quotedblright',\n",
              "      150,\n",
              "      '/endash',\n",
              "      180,\n",
              "      '/acute',\n",
              "      225,\n",
              "      '/aacute',\n",
              "      232,\n",
              "      '/egrave',\n",
              "      '/eacute'],\n",
              "     '/Type': '/Encoding'},\n",
              "    '/FirstChar': 2,\n",
              "    '/FontDescriptor': {'/Ascent': 690,\n",
              "     '/CapHeight': 690,\n",
              "     '/CharSet': '/A/B/C/D/E/F/G/H/I/J/K/L/M/N/O/P/Q/R/S/T/U/V/W/a/b/c/comma/d/e/eight/f/fi/five/four/g/h/hyphen/i/j/k/l/m/n/nine/o/one/p/period/r/s/seven/six/t/three/two/u/v/w/x/y/z/zero',\n",
              "     '/Descent': -209,\n",
              "     '/Flags': 4,\n",
              "     '/FontBBox': [-168, -341, 1000, 960],\n",
              "     '/FontFile': {'/Filter': '/FlateDecode',\n",
              "      '/Length1': 1626,\n",
              "      '/Length2': 15080,\n",
              "      '/Length3': 0},\n",
              "     '/FontName': '/GDFGMZ+NimbusRomNo9L-Medi',\n",
              "     '/ItalicAngle': 0,\n",
              "     '/StemV': 140,\n",
              "     '/Type': '/FontDescriptor',\n",
              "     '/XHeight': 461},\n",
              "    '/LastChar': 122,\n",
              "    '/Subtype': '/Type1',\n",
              "    '/ToUnicode': {'/Filter': '/FlateDecode'},\n",
              "    '/Type': '/Font',\n",
              "    '/Widths': [556,\n",
              "     556,\n",
              "     167,\n",
              "     333,\n",
              "     667,\n",
              "     278,\n",
              "     333,\n",
              "     333,\n",
              "     0,\n",
              "     333,\n",
              "     570,\n",
              "     0,\n",
              "     667,\n",
              "     444,\n",
              "     333,\n",
              "     278,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     333,\n",
              "     278,\n",
              "     250,\n",
              "     333,\n",
              "     555,\n",
              "     500,\n",
              "     500,\n",
              "     1000,\n",
              "     833,\n",
              "     333,\n",
              "     333,\n",
              "     333,\n",
              "     500,\n",
              "     570,\n",
              "     250,\n",
              "     333,\n",
              "     250,\n",
              "     278,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     333,\n",
              "     333,\n",
              "     570,\n",
              "     570,\n",
              "     570,\n",
              "     500,\n",
              "     930,\n",
              "     722,\n",
              "     667,\n",
              "     722,\n",
              "     722,\n",
              "     667,\n",
              "     611,\n",
              "     778,\n",
              "     778,\n",
              "     389,\n",
              "     500,\n",
              "     778,\n",
              "     667,\n",
              "     944,\n",
              "     722,\n",
              "     778,\n",
              "     611,\n",
              "     778,\n",
              "     722,\n",
              "     556,\n",
              "     667,\n",
              "     722,\n",
              "     722,\n",
              "     1000,\n",
              "     722,\n",
              "     722,\n",
              "     667,\n",
              "     333,\n",
              "     278,\n",
              "     333,\n",
              "     581,\n",
              "     500,\n",
              "     333,\n",
              "     500,\n",
              "     556,\n",
              "     444,\n",
              "     556,\n",
              "     444,\n",
              "     333,\n",
              "     500,\n",
              "     556,\n",
              "     278,\n",
              "     333,\n",
              "     556,\n",
              "     278,\n",
              "     833,\n",
              "     556,\n",
              "     500,\n",
              "     556,\n",
              "     556,\n",
              "     444,\n",
              "     389,\n",
              "     333,\n",
              "     556,\n",
              "     500,\n",
              "     722,\n",
              "     500,\n",
              "     500,\n",
              "     444]},\n",
              "   '/F122': {'/BaseFont': '/TAKOGO+NimbusRomNo9L-Regu',\n",
              "    '/Encoding': {'/Differences': [2,\n",
              "      '/fi',\n",
              "      34,\n",
              "      '/quotedbl',\n",
              "      37,\n",
              "      '/percent',\n",
              "      39,\n",
              "      '/quoteright',\n",
              "      '/parenleft',\n",
              "      '/parenright',\n",
              "      43,\n",
              "      '/plus',\n",
              "      '/comma',\n",
              "      '/hyphen',\n",
              "      '/period',\n",
              "      48,\n",
              "      '/zero',\n",
              "      '/one',\n",
              "      '/two',\n",
              "      '/three',\n",
              "      '/four',\n",
              "      '/five',\n",
              "      '/six',\n",
              "      '/seven',\n",
              "      '/eight',\n",
              "      '/nine',\n",
              "      '/colon',\n",
              "      '/semicolon',\n",
              "      63,\n",
              "      '/question',\n",
              "      65,\n",
              "      '/A',\n",
              "      '/B',\n",
              "      '/C',\n",
              "      '/D',\n",
              "      '/E',\n",
              "      '/F',\n",
              "      '/G',\n",
              "      '/H',\n",
              "      '/I',\n",
              "      '/J',\n",
              "      '/K',\n",
              "      '/L',\n",
              "      '/M',\n",
              "      '/N',\n",
              "      '/O',\n",
              "      '/P',\n",
              "      '/Q',\n",
              "      '/R',\n",
              "      '/S',\n",
              "      '/T',\n",
              "      '/U',\n",
              "      '/V',\n",
              "      '/W',\n",
              "      '/X',\n",
              "      '/Y',\n",
              "      '/Z',\n",
              "      '/bracketleft',\n",
              "      93,\n",
              "      '/bracketright',\n",
              "      96,\n",
              "      '/quoteleft',\n",
              "      '/a',\n",
              "      '/b',\n",
              "      '/c',\n",
              "      '/d',\n",
              "      '/e',\n",
              "      '/f',\n",
              "      '/g',\n",
              "      '/h',\n",
              "      '/i',\n",
              "      '/j',\n",
              "      '/k',\n",
              "      '/l',\n",
              "      '/m',\n",
              "      '/n',\n",
              "      '/o',\n",
              "      '/p',\n",
              "      '/q',\n",
              "      '/r',\n",
              "      '/s',\n",
              "      '/t',\n",
              "      '/u',\n",
              "      '/v',\n",
              "      '/w',\n",
              "      '/x',\n",
              "      '/y',\n",
              "      '/z',\n",
              "      147,\n",
              "      '/quotedblleft',\n",
              "      '/quotedblright',\n",
              "      150,\n",
              "      '/endash',\n",
              "      180,\n",
              "      '/acute',\n",
              "      225,\n",
              "      '/aacute',\n",
              "      232,\n",
              "      '/egrave',\n",
              "      '/eacute'],\n",
              "     '/Type': '/Encoding'},\n",
              "    '/FirstChar': 2,\n",
              "    '/FontDescriptor': {'/Ascent': 678,\n",
              "     '/CapHeight': 651,\n",
              "     '/CharSet': '/A/B/C/D/E/F/G/H/I/J/K/L/M/N/O/P/R/S/T/U/V/W/X/Y/Z/a/aacute/acute/b/bracketleft/bracketright/c/colon/comma/d/e/eacute/egrave/eight/endash/f/fi/five/four/g/h/hyphen/i/j/k/l/m/n/nine/o/one/p/parenleft/parenright/percent/period/plus/q/question/quotedbl/quotedblleft/quotedblright/quoteleft/quoteright/r/s/semicolon/seven/six/t/three/two/u/v/w/x/y/z/zero',\n",
              "     '/Descent': -216,\n",
              "     '/Flags': 4,\n",
              "     '/FontBBox': [-168, -281, 1000, 924],\n",
              "     '/FontFile': {'/Filter': '/FlateDecode',\n",
              "      '/Length1': 1630,\n",
              "      '/Length2': 18858,\n",
              "      '/Length3': 0},\n",
              "     '/FontName': '/TAKOGO+NimbusRomNo9L-Regu',\n",
              "     '/ItalicAngle': 0,\n",
              "     '/StemV': 85,\n",
              "     '/Type': '/FontDescriptor',\n",
              "     '/XHeight': 450},\n",
              "    '/LastChar': 233,\n",
              "    '/Subtype': '/Type1',\n",
              "    '/ToUnicode': {'/Filter': '/FlateDecode'},\n",
              "    '/Type': '/Font',\n",
              "    '/Widths': [556,\n",
              "     556,\n",
              "     167,\n",
              "     333,\n",
              "     611,\n",
              "     278,\n",
              "     333,\n",
              "     333,\n",
              "     0,\n",
              "     333,\n",
              "     564,\n",
              "     0,\n",
              "     611,\n",
              "     444,\n",
              "     333,\n",
              "     278,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     333,\n",
              "     180,\n",
              "     250,\n",
              "     333,\n",
              "     408,\n",
              "     500,\n",
              "     500,\n",
              "     833,\n",
              "     778,\n",
              "     333,\n",
              "     333,\n",
              "     333,\n",
              "     500,\n",
              "     564,\n",
              "     250,\n",
              "     333,\n",
              "     250,\n",
              "     278,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     278,\n",
              "     278,\n",
              "     564,\n",
              "     564,\n",
              "     564,\n",
              "     444,\n",
              "     921,\n",
              "     722,\n",
              "     667,\n",
              "     667,\n",
              "     722,\n",
              "     611,\n",
              "     556,\n",
              "     722,\n",
              "     722,\n",
              "     333,\n",
              "     389,\n",
              "     722,\n",
              "     611,\n",
              "     889,\n",
              "     722,\n",
              "     722,\n",
              "     556,\n",
              "     722,\n",
              "     667,\n",
              "     556,\n",
              "     611,\n",
              "     722,\n",
              "     722,\n",
              "     944,\n",
              "     722,\n",
              "     722,\n",
              "     611,\n",
              "     333,\n",
              "     278,\n",
              "     333,\n",
              "     469,\n",
              "     500,\n",
              "     333,\n",
              "     444,\n",
              "     500,\n",
              "     444,\n",
              "     500,\n",
              "     444,\n",
              "     333,\n",
              "     500,\n",
              "     500,\n",
              "     278,\n",
              "     278,\n",
              "     500,\n",
              "     278,\n",
              "     778,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     333,\n",
              "     389,\n",
              "     278,\n",
              "     500,\n",
              "     500,\n",
              "     722,\n",
              "     500,\n",
              "     500,\n",
              "     444,\n",
              "     480,\n",
              "     200,\n",
              "     480,\n",
              "     541,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     333,\n",
              "     500,\n",
              "     444,\n",
              "     1000,\n",
              "     500,\n",
              "     500,\n",
              "     333,\n",
              "     1000,\n",
              "     556,\n",
              "     333,\n",
              "     889,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     0,\n",
              "     444,\n",
              "     444,\n",
              "     350,\n",
              "     500,\n",
              "     1000,\n",
              "     333,\n",
              "     980,\n",
              "     389,\n",
              "     333,\n",
              "     722,\n",
              "     0,\n",
              "     0,\n",
              "     722,\n",
              "     0,\n",
              "     333,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     200,\n",
              "     500,\n",
              "     333,\n",
              "     760,\n",
              "     276,\n",
              "     500,\n",
              "     564,\n",
              "     333,\n",
              "     760,\n",
              "     333,\n",
              "     400,\n",
              "     564,\n",
              "     300,\n",
              "     300,\n",
              "     333,\n",
              "     500,\n",
              "     453,\n",
              "     250,\n",
              "     333,\n",
              "     300,\n",
              "     310,\n",
              "     500,\n",
              "     750,\n",
              "     750,\n",
              "     750,\n",
              "     444,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     889,\n",
              "     667,\n",
              "     611,\n",
              "     611,\n",
              "     611,\n",
              "     611,\n",
              "     333,\n",
              "     333,\n",
              "     333,\n",
              "     333,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     564,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     722,\n",
              "     556,\n",
              "     500,\n",
              "     444,\n",
              "     444,\n",
              "     444,\n",
              "     444,\n",
              "     444,\n",
              "     444,\n",
              "     667,\n",
              "     444,\n",
              "     444,\n",
              "     444]},\n",
              "   '/F28': {'/BaseFont': '/BZZFHX+CMR10',\n",
              "    '/FirstChar': 37,\n",
              "    '/FontDescriptor': {'/Ascent': 694,\n",
              "     '/CapHeight': 683,\n",
              "     '/CharSet': '/eight/parenleft/parenright/percent',\n",
              "     '/Descent': -194,\n",
              "     '/Flags': 4,\n",
              "     '/FontBBox': [-40, -250, 1009, 750],\n",
              "     '/FontFile': {'/Filter': '/FlateDecode',\n",
              "      '/Length1': 1432,\n",
              "      '/Length2': 8486,\n",
              "      '/Length3': 0},\n",
              "     '/FontName': '/BZZFHX+CMR10',\n",
              "     '/ItalicAngle': 0,\n",
              "     '/StemV': 69,\n",
              "     '/Type': '/FontDescriptor',\n",
              "     '/XHeight': 431},\n",
              "    '/LastChar': 56,\n",
              "    '/Subtype': '/Type1',\n",
              "    '/ToUnicode': {'/Filter': '/FlateDecode'},\n",
              "    '/Type': '/Font',\n",
              "    '/Widths': [833.3,\n",
              "     777.8,\n",
              "     277.8,\n",
              "     388.9,\n",
              "     388.9,\n",
              "     500,\n",
              "     777.8,\n",
              "     277.8,\n",
              "     333.3,\n",
              "     277.8,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500]},\n",
              "   '/F65': {'/BaseFont': '/OCEAPE+Inconsolatazi4-Regular',\n",
              "    '/Encoding': {'/Differences': [44,\n",
              "      '/comma',\n",
              "      '/hyphen',\n",
              "      '/period',\n",
              "      '/slash',\n",
              "      '/zero',\n",
              "      '/one',\n",
              "      '/two',\n",
              "      '/three',\n",
              "      '/four',\n",
              "      '/five',\n",
              "      '/six',\n",
              "      58,\n",
              "      '/colon',\n",
              "      64,\n",
              "      '/at',\n",
              "      97,\n",
              "      '/a',\n",
              "      '/b',\n",
              "      '/c',\n",
              "      '/d',\n",
              "      '/e',\n",
              "      103,\n",
              "      '/g',\n",
              "      '/h',\n",
              "      '/i',\n",
              "      '/j',\n",
              "      '/k',\n",
              "      '/l',\n",
              "      '/m',\n",
              "      '/n',\n",
              "      '/o',\n",
              "      '/p',\n",
              "      114,\n",
              "      '/r',\n",
              "      '/s',\n",
              "      '/t',\n",
              "      '/u',\n",
              "      '/v',\n",
              "      '/w',\n",
              "      '/x',\n",
              "      '/y',\n",
              "      123,\n",
              "      '/braceleft',\n",
              "      125,\n",
              "      '/braceright'],\n",
              "     '/Type': '/Encoding'},\n",
              "    '/FirstChar': 44,\n",
              "    '/FontDescriptor': {'/Ascent': 658,\n",
              "     '/CapHeight': 629,\n",
              "     '/CharSet': '/a/at/b/braceleft/braceright/c/colon/comma/d/e/five/four/g/h/hyphen/i/j/k/l/m/n/o/one/p/period/r/s/six/slash/t/three/two/u/v/w/x/y/zero',\n",
              "     '/Descent': -174,\n",
              "     '/Flags': 4,\n",
              "     '/FontBBox': [0, -177, 509, 835],\n",
              "     '/FontFile': {'/Filter': '/FlateDecode',\n",
              "      '/Length1': 2202,\n",
              "      '/Length2': 13550,\n",
              "      '/Length3': 0},\n",
              "     '/FontName': '/OCEAPE+Inconsolatazi4-Regular',\n",
              "     '/ItalicAngle': 0,\n",
              "     '/StemV': 72,\n",
              "     '/Type': '/FontDescriptor',\n",
              "     '/XHeight': 457},\n",
              "    '/LastChar': 125,\n",
              "    '/Subtype': '/Type1',\n",
              "    '/ToUnicode': {'/Filter': '/FlateDecode'},\n",
              "    '/Type': '/Font',\n",
              "    '/Widths': [500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500,\n",
              "     500]}},\n",
              "  '/ProcSet': ['/PDF', '/Text']},\n",
              " '/Type': '/Page'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "9iyDZ9iMGMOY",
        "outputId": "65fa0895-d4e7-4791-9d36-7bc27e954c5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Part-of-speech Tagging for Extremely Low-resource Indian Languages\\nSanjeev Kumar, Preethi Jyothi, Pushpak Bhattacharyya\\nComputer Science and Engineering, IIT Bombay, India\\n{sanjeev, pjyothi, pb}@cse.iitb.ac.in\\nAbstract\\nModern natural language processing (NLP) sys-\\ntems thrive when given access to large datasets.\\nHowever, a large fraction of the world’s lan-\\nguages are not privy to such benefits due to\\nsparse documentation and inadequate digital\\nrepresentation. This is especially true for In-\\ndian regional languages. As a first step towards\\nexpanding the reach of NLP technologies to\\nextremely low-resource Indian languages, we\\npresent a new parallel part-of-speech (POS)\\nevaluation dataset for Angika, Magahi, Bho-\\njpuri and Hindi. Angika, Magahi, Bhojpuri,\\nalong with the more well-known Hindi, are all\\nlanguages spoken in the Indian states of Bi-\\nhar, Jharkhand and West Bengal. Ours is no-\\ntably the first NLP resource, even for a shallow\\nNLP task like POS-tagging, for Angika. We\\nestablish POS-tagging baselines using state-of-\\nthe-art multilingual pretrained language models\\n(PLMs) finetuned on Hindi data, and show zero-\\nshot evaluations on the other three languages.\\nWhile all four languages use the same Devana-\\ngari script, pretrained tokenizers underperform\\nin zero-shot on the three languages. We pro-\\npose a simple look-back fix to address the tok-\\nenization challenge yielding F1-score improve-\\nments of up to 8%on Angika, and show how\\nit comes very close to an oracle setting when\\nthe underlying Hindi word is known (and can\\nbe accurately tokenized).\\n1 Introduction\\nIndia is a multilingual country with more than 1369\\nlanguages and five main language families (Office\\nof the Registrar General Census Commissioner,\\n2022). While the Indian constitution officially rec-\\nognizes 22 languages, numerous others face a bat-\\ntle for survival. English is spoken by only roughly\\n10% of the population (Office of the Registrar Gen-\\neral Census Commissioner, 2022) in India; the\\nmajority prefers their diverse regional languages\\ndeeply rooted in cultural heritage. Building tech-\\nnologies for regional Indian languages is importantto ensure inclusivity across user groups and em-\\npower people for everyday interactions.\\nWhile there has been progress towards promot-\\ning multilinguality and linguistic diversity across\\nIndian languages with tools like IndicNLPSuite\\n(Kakwani et al., 2020) and multilingual corpora\\nsuch as Common Crawl Oscar Corpus (Wenzek\\net al., 2019), PMIndia (Haddow and Kirefu, 2020),\\nand Samanantar (Ramesh et al., 2021), there is\\nalmost no representation of low-resource Indian\\nlanguages like Angika in these resources.\\nIn this work, we focus on three very low-\\nresource Indian languages Angika, Magahi and\\nBhojpuri and create parallel POS-tagging evalu-\\nation corpora for these three languages, consis-\\ntent with Universal Dependencies (UD) guide-\\nlines. These are the first UD-compliant datasets\\nfor Angika and Magahi. We also create a Hindi\\nPOS-tagging dataset that is parallel to the data\\nin the three languages. Hindi is the closest high-\\nresource Indian language that is related to Bhojpuri,\\nAngika and Magahi. This allows us to carefully\\nexamine the cross-lingual performance gap com-\\npared to Hindi, whether transfer from a related\\nhigh-resource language like Hindi is possible, and\\nchallenges related to tokenization that affect zero-\\nshot performance on the low-resource languages.\\nWe propose a simple look-back scheme that cir-\\ncumvents most errors that stem due to suboptimal\\ntokenization for the three low-resource languages.\\nTo encourage further work on these languages, we\\npublicly release our new dataset and code to repro-\\nduce all our experiments1.\\n2 Related Work\\nShallow NLP tasks such as POS tagging for low-\\nresource languages have been studied fairly exten-\\nsively in prior work, many of which have explored\\ncross-lingual transfer learning techniques. Fang\\n1https://www.github.com/snjev310/acl-24-pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pages[0].extract_text()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "for page in pages:\n",
        "  documents.append(page.extract_text())"
      ],
      "metadata": {
        "id": "Ro5Z3QCdHktZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "MMAgiOk1MQWm",
        "outputId": "8c0381dc-d116-4da2-d2cc-90503a8fd845"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Part-of-speech Tagging for Extremely Low-resource Indian Languages\\nSanjeev Kumar, Preethi Jyothi, Pushpak Bhattacharyya\\nComputer Science and Engineering, IIT Bombay, India\\n{sanjeev, pjyothi, pb}@cse.iitb.ac.in\\nAbstract\\nModern natural language processing (NLP) sys-\\ntems thrive when given access to large datasets.\\nHowever, a large fraction of the world’s lan-\\nguages are not privy to such benefits due to\\nsparse documentation and inadequate digital\\nrepresentation. This is especially true for In-\\ndian regional languages. As a first step towards\\nexpanding the reach of NLP technologies to\\nextremely low-resource Indian languages, we\\npresent a new parallel part-of-speech (POS)\\nevaluation dataset for Angika, Magahi, Bho-\\njpuri and Hindi. Angika, Magahi, Bhojpuri,\\nalong with the more well-known Hindi, are all\\nlanguages spoken in the Indian states of Bi-\\nhar, Jharkhand and West Bengal. Ours is no-\\ntably the first NLP resource, even for a shallow\\nNLP task like POS-tagging, for Angika. We\\nestablish POS-tagging baselines using state-of-\\nthe-art multilingual pretrained language models\\n(PLMs) finetuned on Hindi data, and show zero-\\nshot evaluations on the other three languages.\\nWhile all four languages use the same Devana-\\ngari script, pretrained tokenizers underperform\\nin zero-shot on the three languages. We pro-\\npose a simple look-back fix to address the tok-\\nenization challenge yielding F1-score improve-\\nments of up to 8%on Angika, and show how\\nit comes very close to an oracle setting when\\nthe underlying Hindi word is known (and can\\nbe accurately tokenized).\\n1 Introduction\\nIndia is a multilingual country with more than 1369\\nlanguages and five main language families (Office\\nof the Registrar General Census Commissioner,\\n2022). While the Indian constitution officially rec-\\nognizes 22 languages, numerous others face a bat-\\ntle for survival. English is spoken by only roughly\\n10% of the population (Office of the Registrar Gen-\\neral Census Commissioner, 2022) in India; the\\nmajority prefers their diverse regional languages\\ndeeply rooted in cultural heritage. Building tech-\\nnologies for regional Indian languages is importantto ensure inclusivity across user groups and em-\\npower people for everyday interactions.\\nWhile there has been progress towards promot-\\ning multilinguality and linguistic diversity across\\nIndian languages with tools like IndicNLPSuite\\n(Kakwani et al., 2020) and multilingual corpora\\nsuch as Common Crawl Oscar Corpus (Wenzek\\net al., 2019), PMIndia (Haddow and Kirefu, 2020),\\nand Samanantar (Ramesh et al., 2021), there is\\nalmost no representation of low-resource Indian\\nlanguages like Angika in these resources.\\nIn this work, we focus on three very low-\\nresource Indian languages Angika, Magahi and\\nBhojpuri and create parallel POS-tagging evalu-\\nation corpora for these three languages, consis-\\ntent with Universal Dependencies (UD) guide-\\nlines. These are the first UD-compliant datasets\\nfor Angika and Magahi. We also create a Hindi\\nPOS-tagging dataset that is parallel to the data\\nin the three languages. Hindi is the closest high-\\nresource Indian language that is related to Bhojpuri,\\nAngika and Magahi. This allows us to carefully\\nexamine the cross-lingual performance gap com-\\npared to Hindi, whether transfer from a related\\nhigh-resource language like Hindi is possible, and\\nchallenges related to tokenization that affect zero-\\nshot performance on the low-resource languages.\\nWe propose a simple look-back scheme that cir-\\ncumvents most errors that stem due to suboptimal\\ntokenization for the three low-resource languages.\\nTo encourage further work on these languages, we\\npublicly release our new dataset and code to repro-\\nduce all our experiments1.\\n2 Related Work\\nShallow NLP tasks such as POS tagging for low-\\nresource languages have been studied fairly exten-\\nsively in prior work, many of which have explored\\ncross-lingual transfer learning techniques. Fang\\n1https://www.github.com/snjev310/acl-24-pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(documents))\n",
        "print()\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaNH5y54Ltk3",
        "outputId": "a49dd8b4-b7f5-45a5-cc1c-f80707463d40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Part-of-speech Tagging for Extremely Low-resource Indian Languages\\nSanjeev Kumar, Preethi Jyothi, Pushpak Bhattacharyya\\nComputer Science and Engineering, IIT Bombay, India\\n{sanjeev, pjyothi, pb}@cse.iitb.ac.in\\nAbstract\\nModern natural language processing (NLP) sys-\\ntems thrive when given access to large datasets.\\nHowever, a large fraction of the world’s lan-\\nguages are not privy to such benefits due to\\nsparse documentation and inadequate digital\\nrepresentation. This is especially true for In-\\ndian regional languages. As a first step towards\\nexpanding the reach of NLP technologies to\\nextremely low-resource Indian languages, we\\npresent a new parallel part-of-speech (POS)\\nevaluation dataset for Angika, Magahi, Bho-\\njpuri and Hindi. Angika, Magahi, Bhojpuri,\\nalong with the more well-known Hindi, are all\\nlanguages spoken in the Indian states of Bi-\\nhar, Jharkhand and West Bengal. Ours is no-\\ntably the first NLP resource, even for a shallow\\nNLP task like POS-tagging, for Angika. We\\nestablish POS-tagging baselines using state-of-\\nthe-art multilingual pretrained language models\\n(PLMs) finetuned on Hindi data, and show zero-\\nshot evaluations on the other three languages.\\nWhile all four languages use the same Devana-\\ngari script, pretrained tokenizers underperform\\nin zero-shot on the three languages. We pro-\\npose a simple look-back fix to address the tok-\\nenization challenge yielding F1-score improve-\\nments of up to 8%on Angika, and show how\\nit comes very close to an oracle setting when\\nthe underlying Hindi word is known (and can\\nbe accurately tokenized).\\n1 Introduction\\nIndia is a multilingual country with more than 1369\\nlanguages and five main language families (Office\\nof the Registrar General Census Commissioner,\\n2022). While the Indian constitution officially rec-\\nognizes 22 languages, numerous others face a bat-\\ntle for survival. English is spoken by only roughly\\n10% of the population (Office of the Registrar Gen-\\neral Census Commissioner, 2022) in India; the\\nmajority prefers their diverse regional languages\\ndeeply rooted in cultural heritage. Building tech-\\nnologies for regional Indian languages is importantto ensure inclusivity across user groups and em-\\npower people for everyday interactions.\\nWhile there has been progress towards promot-\\ning multilinguality and linguistic diversity across\\nIndian languages with tools like IndicNLPSuite\\n(Kakwani et al., 2020) and multilingual corpora\\nsuch as Common Crawl Oscar Corpus (Wenzek\\net al., 2019), PMIndia (Haddow and Kirefu, 2020),\\nand Samanantar (Ramesh et al., 2021), there is\\nalmost no representation of low-resource Indian\\nlanguages like Angika in these resources.\\nIn this work, we focus on three very low-\\nresource Indian languages Angika, Magahi and\\nBhojpuri and create parallel POS-tagging evalu-\\nation corpora for these three languages, consis-\\ntent with Universal Dependencies (UD) guide-\\nlines. These are the first UD-compliant datasets\\nfor Angika and Magahi. We also create a Hindi\\nPOS-tagging dataset that is parallel to the data\\nin the three languages. Hindi is the closest high-\\nresource Indian language that is related to Bhojpuri,\\nAngika and Magahi. This allows us to carefully\\nexamine the cross-lingual performance gap com-\\npared to Hindi, whether transfer from a related\\nhigh-resource language like Hindi is possible, and\\nchallenges related to tokenization that affect zero-\\nshot performance on the low-resource languages.\\nWe propose a simple look-back scheme that cir-\\ncumvents most errors that stem due to suboptimal\\ntokenization for the three low-resource languages.\\nTo encourage further work on these languages, we\\npublicly release our new dataset and code to repro-\\nduce all our experiments1.\\n2 Related Work\\nShallow NLP tasks such as POS tagging for low-\\nresource languages have been studied fairly exten-\\nsively in prior work, many of which have explored\\ncross-lingual transfer learning techniques. Fang\\n1https://www.github.com/snjev310/acl-24-pos',\n",
              " 'and Cohn (2016) achieve successful POS tagging,\\nespecially in low-resource languages (like Mala-\\ngasy and Kinyarwanda), by combining word align-\\nment with gold-standard data. Kim et al. (2017) im-\\nplemented a BiLSTM model that utilizes word and\\ncharacter embeddings to transfer knowledge with-\\nout relying on parallel corpora. Another approach\\nby Huck et al. (2019) introduces zero-shot tag-\\nging, by projecting annotations from a related high-\\nresource language, such as Russian for Ukrainian.\\nMore recently, Dione et al. (2023) demonstrated\\nsignificant improvements in POS tagging by using\\nmultilingual pretrained LMs trained on typologi-\\ncally diverse African languages. Recent work has\\nalso employed modular learning (Lin et al., 2019;\\nArtetxe et al., 2020; Pfeiffer et al., 2020; Min et al.,\\n2023) techniques with multilingual pretrained lan-\\nguage models (PLMs) to enable effective cross-\\nlingual transfer to low-resource languages. Prior\\nwork on POS tagging for various low-resource\\nIndo-Aryan languages has mainly utilized classical\\nNLP techniques and do not leverage PLMs. For\\nexample, Saharia et al. (2009) developed a POS\\ntagger for Assamese and Basit and Kumar (2019)\\nfor Awadhi, and both works used an HMM model.\\nAmong the four languages of interest, other than\\nHindi, there is an existing UD-compliant POS-\\ntagging evaluation dataset for Bhojpuri (Ojha and\\nZeman, 2020). However, it only has 268 sentences.\\nOverall, there is a strong need for NLP datasets\\ncovering extremely low-resource Indian languages\\n(such as Angika). We think it is also useful to de-\\nvelop parallel datasets along with relatively higher-\\nresource languages (such as Hindi) that share com-\\nmon geographical boundaries, word order, script,\\nand language family. This helps understand how\\ncross-lingual transfer can be more effectively uti-\\nlized from high-resource languages.\\n3 Data Collection and Annotation\\nWe created a parallel corpus comprising 708 evalu-\\nation sentences each for Hindi, Angika, Bhojpuri,\\nand Magahi. We used some Hindi monolingual\\ndata from Kunchukuttan et al. (2018) and trans-\\nlated into Angika, Magahi, and Bhojpuri. Some\\nAngika monolingual data was extracted from the\\nwebonary2Angika dictionary and translated into\\nHindi and the other two languages. The UD dataset\\nprimarily draws data from the news domain, re-\\nsulting in a higher frequency of named entities\\n2https://www.webonary.org/angika/belonging to the noun class. To improve diversity,\\nwe incorporated sentences of daily conversations\\nand regional stories. Additionally, we included a\\nfew frequently used sentences by native speakers.\\nIssues in the webonary Angika dictionary such as\\nword misspellings and missing sentences were man-\\nually addressed. Languages were translated by re-\\nspective language annotators and verified by native\\nspeakers. Table 4 in Appendix A.2 provides more\\ndetails for all four languages and Appendix A.4 pro-\\nvides more details about our measures for quality\\ncontrol in the annotations.\\n4 Experiments and Results\\nWe provide POS tagging baselines using multi-\\nlingual PLMs in a zero-shot setting. We fine-\\ntune an Indic-specific multilingual PLM (MURIL\\n(Khanuja et al., 2021)) on Hindi UD POS-tagging\\ndata consisting of 13K sentences. We refer to this\\nmodel as “Hindi FT\". We also fine-tuned on other\\nmassively multilingual PLMs, XLM-R-large (Con-\\nneau et al., 2020) and RemBERT (Chung et al.,\\n2020)), as a comparison to MURIL. All three PLMs\\nhave been pretrained on around 100-110 languages,\\nwith the exception of MuRIL, which is exclusively\\npretrained on 12 major Indic languages. How-\\never, none of these models are pretrained on any\\nof the low-resource languages that we explore in\\nthis work. More details regarding the experimental\\nsetup can be found in Appendix A.5.\\n4.1 Baseline Models\\nTable 1 presents the zero-shot POS tagging results\\nfor all three low-resource languages (under “Hindi\\nFT\"). MuRIL has a slight advantage over XLM-R\\nand RemBERT in the zero-shot setting. MuRIL is\\nsignificantly smaller in size, compared to XLM-R-\\nlarge and RemBERT. However, it performs best on\\nthe low-resource languages possibly by benefiting\\nfrom its Indic-only pretraining, as opposed to the\\nother PLMs that will have language interference\\nfrom many non-Indic languages.\\nWe also evaluate MuRIL on publicly available\\nUD Hindi test data to validate our model setup. On\\nthe UD Hindi test data, MuRIL achieves an F1-\\nscore of 0.96, which is comparable to the F1-score\\nwe obtained on our Hindi evaluation set (0.93).\\nThis validates our model setup and acts as a sanity\\ncheck for the quality of our Hindi data.',\n",
              " 'Hindi Angika Magahi Bhojpuri\\nP R F1 P R F1 P R F1 P R F1\\nHindi FT MuRIL 0.93 0.94 0.93 0.66 0.72 0.69 0.74 0.78 0.76 0.78 0.80 0.79\\nXLM-R large 0.93 0.93 0.93 0.68 0.69 0.69 0.73 0.74 0.74 0.76 0.77 0.76\\nRemBERT 0.93 0.94 0.94 0.67 0.71 0.69 0.75 0.77 0.76 0.76 0.77 0.76\\nA VG 0.93 0.94 0.93 0.67 0.71 0.69 0.74 0.76 0.75 0.76 0.77 0.77\\nLook-back MuRIL 0.95 0.94 0.94 0.80 0.77 0.77 0.84 0.82 0.83 0.85 0.83 0.84\\nXLM-R large 0.95 0.95 0.95 0.78 0.73 0.74 0.81 0.76 0.77 0.80 0.75 0.75\\nRemBERT 0.94 0.94 0.94 0.79 0.73 0.74 0.82 0.79 0.80 0.82 0.78 0.79\\nA VG 0.95 0.94 0.94 0.79 0.74 0.75 0.82 0.79 0.80 0.83 0.79 0.79\\nLook-back MuRIL 0.95 0.95 0.95 0.80 0.76 0.77 0.83 0.81 0.82 0.85 0.82 0.83\\nwith score XLM-R large 0.95 0.94 0.94 0.79 0.74 0.75 0.83 0.80 0.80 0.83 0.80 0.80\\nRemBERT 0.95 0.95 0.95 0.80 0.75 0.76 0.83 0.81 0.81 0.84 0.81 0.81\\nA VG 0.95 0.95 0.95 0.80 0.75 0.76 0.83 0.81 0.81 0.84 0.81 0.81\\nTable 1: POS tagging Precision ( P), Recall ( R), and F1-score ( F1) of three PLMs evaluated on our parallel dataset\\nusing zero-shot, look-back, and look-back-with-score methods. Results range from 0 to 1 and are averaged across\\nfive random seeds.\\n4.2 Tokenization Inconsistencies\\nIn the case of extremely low-resource languages,\\na pretrained tokenizer tends to break words into\\nmultiple sub-word tokens. In our experiments, we\\npredict POS tags for each token. Thus, sub-optimal\\ntokenization can result in poor quality predictions.\\nFor extremely low-resource languages, words may\\nbe split all the way down into individual characters\\nwhich makes the POS predictions even noisier. In\\nSection 4.3, we propose a simple look-back scheme\\nto alleviate some of the issues that stem from poor\\ntokenization. In Section 4.4, we analyze how much\\nwe could make up for tokenization challenges in\\nan oracle setting if we had access to parallel data\\nin Hindi.\\n4.3 Investigating the impact of sub-word\\nWhen a tokenizer breaks down words into sub-\\nwords, these sub-words can get different tags. Poor\\ntokenization that leads to over-fragmentation ex-\\nacerbates this problem. In our quantitative dataset\\nanalysis, we observed that in Angika, Magahi and\\nBhojpuri around 45% of words were split into 2, 3,\\nand 4 sub-word tokens. To address this challenge,\\nwe introduce two simple techniques: look-back and\\nlook-back-with-score.\\nLook-back. We substitute the POS tags corre-\\nsponding to all the tokens in a word with the POS\\ntag of the first token. This approach was chosen\\nbecause the first split token closely relates to the\\nword in a higher-resource language, preserving\\nmeaning and POS tags. For example, an Angika\\nword “dEkhAibae\" (will see), splits into “dEkh”\\nand “ibae” here, the word “dEkh” (see) is related\\nto Hindi. The results of this look-back approachare shown in Table 1. We find significant improve-\\nments in performance across all three low-resource\\nlanguages, most notably for Angika.\\nLook-back-with-score. Each token produces\\nlogit values corresponding to the tag distribu-\\ntions. If a word Wis split into nsub-\\nwords (w1, w2, . . . , w n)with corresponding logits\\n(l1, l2, . . . , l n), we find the sub-word token with the\\nmaximum logit score and retrieve its corresponding\\nPOS label. We replace the POS tags of all other\\nsub-word tokens in that word with the POS tag of\\nthe maximum-scoring token.\\nWhen comparing look-back and look-back-with-\\nscore methods in Table 1, the results suggest\\nthat, on average, look-back-with-score outperforms\\nlook-back (+1% increase in F1-score across all\\nlanguages and all models). Our initial observa-\\ntions indicate that tokenizers generally split words\\ninto tokens that are seen in the vocabulary of high-\\nresource languages, and thus replacing the tag of\\nsubsequent tokens with the tag of the first token\\nis a reasonable strategy to mitigate token-level in-\\nconsistencies. However, the “look-back with score”\\napproach utilizes information from tokens within\\na word, and this turns out to offer a small but\\nconsistent advantage across all three languages.\\nThe look-back-with-score approach is less effective\\nfor MuRIL compared to look-back. This may be\\nbecause MuRIL, primarily trained on Indian lan-\\nguages, aligns initial split tokens more closely with\\nHindi, resulting in a higher confidence level for the\\nfirst token than for other split tokens.\\n4.4 Using Hindi Parallel Data\\nHere, we assess the effectiveness of having access\\nto a parallel corpus of a relatively higher resource',\n",
              " 'Hindi Angika Magahi Bhojpuri\\nP R F1 P R F1 P R F1 P R F1\\nHindi FT MuRIL 0.93 0.94 0.93 0.66 0.72 0.69 0.74 0.78 0.76 0.78 0.80 0.79\\nXLM-R large 0.93 0.93 0.93 0.68 0.69 0.69 0.73 0.74 0.74 0.76 0.77 0.76\\nRemBERT 0.93 0.94 0.94 0.67 0.71 0.69 0.75 0.77 0.76 0.76 0.77 0.76\\nA VG 0.93 0.94 0.94 0.67 0.71 0.69 0.74 0.76 0.75 0.76 0.77 0.77\\nOracle MuRIL - - - 0.81 0.78 0.79 0.85 0.84 0.84 0.87 0.85 0.85\\nXLM-R large - - - 0.80 0.76 0.76 0.82 0.79 0.79 0.83 0.80 0.80\\nRemBERT - - - 0.80 0.75 0.76 0.85 0.83 0.83 0.85 0.84 0.84\\nA VG - - - 0.80 0.76 0.77 0.84 0.82 0.82 0.85 0.83 0.83\\nNon-oracle MuRIL - - - 0.70 0.64 0.64 0.73 0.68 0.69 0.75 0.71 0.72\\nXLM-R large - - - 0.57 0.51 0.49 0.64 0.60 0.57 0.67 0.63 0.60\\nRemBERT - - - 0.58 0.50 0.53 0.65 0.59 0.62 0.66 0.61 0.63\\nA VG - - - 0.62 0.55 0.55 0.67 0.63 0.63 0.69 0.65 0.65\\nTable 2: POS tagging Precision ( P), Recall ( R), and F1-scores ( F1) of three PLMs evaluated on our parallel data\\nusing zero-shot (‘Hindi FT’), oracle and non-oracle methods. Results range from 0 to 1 and are averaged across five\\nrandom seeds.\\nlanguage, which shares the script, word order, and\\ngeographical boundaries and can assist in POS tag\\npredictions for extremely low-resource languages.\\nFor this analysis, we have introduced two methods:\\nthe oracle setting, where we have oracle knowledge\\nof incorrectly predicted POS tags, and the non-\\noracle setting, where we lack any prior knowledge\\nof incorrectly predicted POS tags.\\nOracle setting. We compare our model’s predic-\\ntions for Angika, Magahi and Bhojpuri with the\\nground-truth POS tag sequences. For mismatches,\\nwe utilize the parallel corpus in Hindi to identify\\nthe corresponding Hindi token and the most fre-\\nquently occurring tag for the aligned Hindi token.\\nThis tag replaces our model predictions in the other\\nthree low-resource languages.\\nNon-oracle setting. We substitute the predicted\\ntags of a token with the original tags from the par-\\nallel corpus. This involves choosing the tag with\\nthe highest frequency for an aligned Hindi token in\\nthe parallel corpus. In this setting, we achieve F1-\\nscores of 0.67, 0.63, and 0.65 for Angika, Magahi,\\nand Bhojpuri, respectively, which is significantly\\nlower than the scores obtained in the zero-shot and\\noracle settings.\\nTable 2 presents the results of both approaches.\\nWhen comparing the oracle and non-oracle results\\nwith the zero-shot approach, we observe that hav-\\ning access to a parallel corpus in a comparatively\\nhigher-resource language improves the overall tag-\\nging performance, primarily when focusing on\\nwrongly predicted tags. However, since we do not\\nhave apriori information of whether our predicted\\ntag is correct or not, the non-oracle approach of\\nalways replacing it with the Hindi token’s mostfrequent POS tag results in a notable decline in\\nperformance.\\n4.5 Tag-level Analysis\\nTable 1 shows significant improvements in perfor-\\nmance using look-back-with-score over the zero-\\nshot baseline. These methods provide notable\\nperformance gains for tags like pronouns, proper\\nnouns, conjunctions, adjectives, and numbers. We\\nillustrate how a simple strategy like look-back sig-\\nnificantly helps with an example. Consider the\\nAngika sentence “HamMe aArU tOI miLika duGo\\naAma kHaIlIye” (Translation: You and I ate two\\nmangoes together). While a pretrained tokenizer\\ncorrectly identifies “hamMe” as two pronouns in\\nAngika, it might misrecognize their individual tags\\n(“ham” as pronoun, “Me” as adposition). The look-\\nback method leverages contextual information to\\nrectify these errors by correctly predicting both to-\\nkens as pronouns. This results in an improvement\\nover the zero-shot setting. Similar morphological\\nstructures are observed with numerals like “duGo”\\n(meaning “two”). All these languages employ a\\nclassifier as a bound morpheme, with “Go” as the\\nspecific marker for numbers. A broader analysis\\nof the linguistic properties causing errors in the\\nzero-shot setting is discussed in 4.6.\\n4.6 Error Analysis\\nTable 3 shows tag-wise F1-scores for different lan-\\nguages using MuRIL in zero-shot and look-back-\\nwith-score settings. Subordinate conjunctions, pro-\\nnouns, proper nouns, particles, determiners, and\\nadverbs exhibit lower F1-scores compared to other\\ntags. Adjectives and numbers also show lower\\nscores than Hindi and the total occurrences of tags',\n",
              " 'Hindi FT Look-back-with-score\\nTags Hindi Angika Magahi Bhojpuri A VG Hindi Angika Magahi Bhojpuri A VG\\nADJ 0.89 0.68 0.74 0.76 0.73 0.95 0.73 0.74 0.76 0.74\\nADP 0.96 0.82 0.94 0.94 0.90 0.98 0.82 0.94 0.94 0.90\\nADV 0.95 0.36 0.51 0.48 0.45 0.95 0.36 0.49 0.48 0.44\\nAUX 0.96 0.78 0.84 0.81 0.81 0.98 0.78 0.84 0.82 0.81\\nCCONJ 0.93 0.70 0.87 0.88 0.82 0.97 0.89 0.87 0.88 0.88\\nDET 0.8 0.44 0.47 0.59 0.50 0.81 0.43 0.58 0.55 0.52\\nNOUN 0.93 0.83 0.85 0.87 0.85 0.95 0.83 0.85 0.87 0.85\\nNUM 0.9 0.75 0.69 0.74 0.73 0.92 0.75 0.69 0.82 0.75\\nPART 0.91 0.47 0.79 0.75 0.67 0.88 0.44 0.79 0.74 0.66\\nPRON 0.93 0.69 0.7 0.63 0.67 0.96 0.78 0.7 0.75 0.74\\nPROPN 0.85 0.5 0.57 0.49 0.52 0.87 0.64 0.57 0.59 0.60\\nPUNCT 0.98 0.99 0.98 1.00 0.99 0.98 0.99 0.98 1.00 0.99\\nSCONJ 0.83 0.63 0.68 0.63 0.65 0.83 0.63 0.68 0.63 0.65\\nSYM 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\\nVERB 0.95 0.71 0.75 0.82 0.76 0.97 0.74 0.75 0.82 0.76\\nTable 3: Tag-wise F1-scores using MuRIL for POS tags across all languages for the zero-shot baseline (‘Hindi FT’)\\nand ‘look-back-with-score’ method. Average (A VG) is calculated using Angika, Magahi, and Bhojpuri scores.\\nin the dataset, particularly when compared to par-\\nticles and determiners. These disparities can be\\nattributed to complexities in word formations and\\na few other linguistic nuances detailed below.\\nTag confusion between subordinate conjunction,\\nadposition, and pronoun. In Angika, Magahi\\nand Bhojpuri, pronouns, adpositions and subordi-\\nnate conjunctions are written similarly. For e.g.:\\nHindi: kyA tum kal aAogI?\\nAngika: kI toI kaAl aAiybae?\\nBhojpuri: kA tu kal aAiyebu?\\nMagahi: kA tu kal aAibhe?\\nEnglish: Will you come tomorrow?\\nIn this example, kyA, kI, and kA are pronouns,\\nbut kI and kA are written as Hindi adposition and\\nsubordinate conjunctions.\\nClassifiers. Angika, Bhojpuri, and Magahi lan-\\nguages often make use of classifier markers (Tho,\\nGo) to accompany numbers (e.g., Ek (one) and dU\\n(two)). Classifier markers in these languages are:\\nTo, Te, go, Ke, etc. Hindi does not exhibit this\\nproperty. For e.g.:\\nHindi: Ek sajJan.\\nAngika: EkTa SajJanA.\\nBhojpuri: EGo sajJanA.\\nMagahi: EaGo sajJanA.\\nEnglish Translation: One gentleman.\\nNon-ergative construction. Hindi is an ergative\\nlanguage, while Angika, Bhojpuri, and Magahi are\\nnon-ergative. In Hindi, when the subject is desig-\\nnated with [ne] (oblique case), the transitive verb\\nagrees with the object in terms of person, number,\\nand gender. For e.g.:\\nHindi: Mohan ne kitaB padi.Angika: Mohane kitaB padhalkae.\\nBhojpuri: Mohane kitaB padhlAs.\\nMaghai: Mohane kitaB padalAi.\\nEnglish Translation: Mohan read the book.\\n5 Conclusion\\nThis paper introduces a UD-compliant parallel POS\\ntag dataset for three extremely low-resource Indian\\nlanguages: Angika, Magahi and Bhojpuri. This\\nwork contributes one of the first NLP resources for\\nthese languages and is a first step towards address-\\ning their under-representation in the digital land-\\nscape. We provide state-of-the-art POS baselines\\nby fine-tuning multilingual PLMs with Hindi data.\\nWe find that pretrained Indic tokenizers adversely\\naffect cross-lingual transfer to Angika, Magahi and\\nBhojpuri which we largely address with a simple\\nlook-back scheme.\\nAcknowledgements\\nThe first author would like to gratefully acknowl-\\nedge a Ph.D. grant from the TCS Research Foun-\\ndation to support his research on extremely low-\\nresource Indian languages. We would like to thank\\nthe anonymous reviewers for their helpful com-\\nments.\\nLimitations\\n1.While we cover three low-resource languages,\\nmany others like Bajjika, Surajpuri, and\\nMaithili, which share geographical boundaries\\nwith our languages of interest, have not been\\nincluded.',\n",
              " '2.Due to the smaller size of our dataset com-\\npared to larger POS datasets, we do not have a\\nlot of diversity across domains. We note that\\nthe POS dataset and the observations in this\\nwork may not be applicable to all domains,\\nsuch as speech transcripts or conversational\\ndata.\\nEthics Statement\\nWe would like to emphasize our commitment to\\nupholding ethical practices throughout this work.\\nWe aimed to ensure that human annotators received\\na fair compensation for their annotation efforts and\\nwas commensurate with the time and effort invested\\nin their work.\\nReferences\\nMikel Artetxe, Sebastian Ruder, and Dani Yogatama.\\n2020. On the cross-lingual transferability of mono-\\nlingual representations. In Proceedings of the 58th\\nAnnual Meeting of the Association for Computational\\nLinguistics , pages 4623–4637, Online. Association\\nfor Computational Linguistics.\\nAbdul Basit and Ritesh Kumar. 2019. Towards a part-of-\\nspeech tagger for awadhi: Corpus and experiments.\\nIn(IJACSA) International Journal of Advanced Com-\\nputer Science and Applications .\\nAlex Brandsen, Suzan Verberne, Milco Wansleeben,\\nand Karsten Lambers. 2020. Creating a dataset for\\nnamed entity recognition in the archaeology domain.\\nInProceedings of the Twelfth Language Resources\\nand Evaluation Conference , pages 4573–4577.\\nRonald Cardenas, Ying Lin, Heng Ji, and Jonathan May.\\n2019. A grounded unsupervised universal part-of-\\nspeech tagger for low-resource languages. In Pro-\\nceedings of the 2019 Conference of the North Amer-\\nican Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume\\n1 (Long and Short Papers) , pages 2428–2439, Min-\\nneapolis, Minnesota. Association for Computational\\nLinguistics.\\nHyung Won Chung, Thibault Fevry, Henry Tsai, Melvin\\nJohnson, and Sebastian Ruder. 2020. Rethinking\\nembedding coupling in pre-trained language models.\\narXiv preprint arXiv:2010.12821 .\\nRichard Oliver Collin. 2010. Ethnologue. Ethnopolitics ,\\n9(3-4):425–432.\\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\\nVishrav Chaudhary, Guillaume Wenzek, Francisco\\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\\nmoyer, and Veselin Stoyanov. 2020. Unsupervisedcross-lingual representation learning at scale. In Pro-\\nceedings of the 58th Annual Meeting of the Asso-\\nciation for Computational Linguistics , pages 8440–\\n8451, Online. Association for Computational Lin-\\nguistics.\\nCheikh M. Bamba Dione, David Ifeoluwa Adelani,\\nPeter Nabende, Jesujoba Alabi, Thapelo Sindane,\\nHappy Buzaaba, Shamsuddeen Hassan Muhammad,\\nChris Chinenye Emezue, Perez Ogayo, Anuoluwapo\\nAremu, Catherine Gitau, Derguene Mbaye, Jonathan\\nMukiibi, Blessing Sibanda, Bonaventure F. P. Dos-\\nsou, Andiswa Bukula, Rooweither Mabuya, Allah-\\nsera Auguste Tapo, Edwin Munkoh-Buabeng, Vic-\\ntoire Memdjokam Koagne, Fatoumata Ouoba Ka-\\nbore, Amelia Taylor, Godson Kalipe, Tebogo\\nMacucwa, Vukosi Marivate, Tajuddeen Gwadabe,\\nMboning Tchiaze Elvis, Ikechukwu Onyenwe, Gra-\\ntien Atindogbe, Tolulope Adelani, Idris Akinade,\\nOlanrewaju Samuel, Marien Nahimana, Théogène\\nMusabeyezu, Emile Niyomutabazi, Ester Chimhenga,\\nKudzai Gotosa, Patrick Mizha, Apelete Agbolo, Sey-\\ndou Traore, Chinedu Uchechukwu, Aliyu Yusuf,\\nMuhammad Abdullahi, and Dietrich Klakow. 2023.\\nMasakhaPOS: Part-of-speech tagging for typolog-\\nically diverse African languages. In Proceedings\\nof the 61st Annual Meeting of the Association for\\nComputational Linguistics (Volume 1: Long Papers) ,\\npages 10883–10900, Toronto, Canada. Association\\nfor Computational Linguistics.\\nMeng Fang and Trevor Cohn. 2016. Learning when\\nto trust distant supervision: An application to low-\\nresource POS tagging using cross-lingual projection.\\nInProceedings of the 20th SIGNLL Conference on\\nComputational Natural Language Learning , pages\\n178–186, Berlin, Germany. Association for Compu-\\ntational Linguistics.\\nJoseph L Fleiss. 1971. Measuring nominal scale agree-\\nment among many raters. Psychological bulletin ,\\n76(5):378.\\nBarry Haddow and Faheem Kirefu. 2020. Pmindia–a\\ncollection of parallel corpora of languages of india.\\narXiv preprint arXiv:2001.09907 .\\nMatthias Huck, Diana Dutka, and Alexander Fraser.\\n2019. Cross-lingual annotation projection is effective\\nfor neural part-of-speech tagging. In Proceedings of\\nthe Sixth Workshop on NLP for Similar Languages,\\nVarieties and Dialects , pages 223–233.\\nDivyanshu Kakwani, Anoop Kunchukuttan, Satish\\nGolla, NC Gokul, Avik Bhattacharyya, Mitesh M\\nKhapra, and Pratyush Kumar. 2020. Indicnlpsuite:\\nMonolingual corpora, evaluation benchmarks and\\npre-trained multilingual language models for indian\\nlanguages. In Findings of the Association for Com-\\nputational Linguistics: EMNLP 2020 , pages 4948–\\n4961.\\nSimran Khanuja, Diksha Bansal, Sarvesh Mehtani,\\nSavya Khosla, Atreyee Dey, Balaji Gopalan,\\nDilip Kumar Margam, Pooja Aggarwal, Rajiv Teja',\n",
              " 'Nagipogu, Shachi Dave, et al. 2021. Muril: Multi-\\nlingual representations for indian languages. arXiv\\npreprint arXiv:2103.10730 .\\nJoo-Kyung Kim, Young-Bum Kim, Ruhi Sarikaya, and\\nEric Fosler-Lussier. 2017. Cross-lingual transfer\\nlearning for pos tagging without cross-lingual re-\\nsources. In Proceedings of the 2017 conference on\\nempirical methods in natural language processing ,\\npages 2832–2838.\\nJan-Christoph Klie, Richard Eckart de Castilho, and\\nIryna Gurevych. 2023. Analyzing dataset annota-\\ntion quality management in the wild. arXiv preprint\\narXiv:2307.08153 .\\nAnoop Kunchukuttan, Pratik Mehta, and Pushpak Bhat-\\ntacharyya. 2018. The IIT Bombay English-Hindi\\nparallel corpus. In Proceedings of the Eleventh In-\\nternational Conference on Language Resources and\\nEvaluation (LREC 2018) , Miyazaki, Japan. European\\nLanguage Resources Association (ELRA).\\nYu-Hsiang Lin, Chian-Yu Chen, Jean Lee, Zirui Li,\\nYuyan Zhang, Mengzhou Xia, Shruti Rijhwani, Junx-\\nian He, Zhisong Zhang, Xuezhe Ma, et al. 2019.\\nChoosing transfer languages for cross-lingual learn-\\ning.arXiv preprint arXiv:1905.12688 .\\nBonan Min, Hayley Ross, Elior Sulem, Amir\\nPouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz,\\nEneko Agirre, Ilana Heintz, and Dan Roth. 2023.\\nRecent advances in natural language processing via\\nlarge pre-trained language models: A survey. ACM\\nComputing Surveys , 56(2):1–40.\\nIndia (ORGI) Office of the Registrar General\\nCensus Commissioner. 2022. Census of In-\\ndia 2011 - LANGUAGE ATLAS - INDIA.\\nhttps://censusindia.gov.in/nada/index.\\nphp/catalog/42561 . [Accessed 05-06-2024].\\nAtul Kr. Ojha and Daniel Zeman. 2020. Universal\\ndependency treebanks for low-resource indian lan-\\nguages: The case of bhojpuri. In Proceedings of the\\nWILDRE5– 5th Workshop on Indian Language Data:\\nResources and Evaluation , pages 33–38, Marseille,\\nFrance. European Language Resources Association\\n(ELRA).\\nJonas Pfeiffer, Ivan Vuli ´c, Iryna Gurevych, and Se-\\nbastian Ruder. 2020. MAD-X: An Adapter-Based\\nFramework for Multi-Task Cross-Lingual Transfer.\\nInProceedings of the 2020 Conference on Empirical\\nMethods in Natural Language Processing (EMNLP) ,\\npages 7654–7673, Online. Association for Computa-\\ntional Linguistics.\\nGowtham Ramesh, Sumanth Doddapaneni, Aravinth\\nBheemaraj, Mayank Jobanputra, Raghavan AK,\\nAjitesh Sharma, Sujit Sahoo, Harshita Diddee, Ma-\\nhalakshmi J, Divyanshu Kakwani, Navneet Kumar,\\nAswin Pradeep, Srihari Nagaraj, Kumar Deepak,\\nVivek Raghavan, Anoop Kunchukuttan, Pratyush Ku-\\nmar, and Mitesh Shantadevi Khapra. 2021. Samanan-\\ntar: The largest publicly available parallel corpora\\ncollection for 11 indic languages.Navanath Saharia, Dhrubajyoti Das, Utpal Sharma, and\\nJugal Kalita. 2009. Part of speech tagger for as-\\nsamese text. In Proceedings of the ACL-IJCNLP\\n2009 Conference Short Papers , pages 33–36.\\nGuillaume Wenzek, Marie-Anne Lachaux, Alexis Con-\\nneau, Vishrav Chaudhary, Francisco Guzmán, Ar-\\nmand Joulin, and Edouard Grave. 2019. Ccnet: Ex-\\ntracting high quality monolingual datasets from web\\ncrawl data. arXiv preprint arXiv:1911.00359 .\\nA Appendix\\nA.1 Extremely low resource languages\\nAn extremely low-resource language has relatively\\nfew or no resources available. Compared to other\\nlanguages, Indian regional languages have lim-\\nited resources. These extremely low-resource lan-\\nguages are often considered less popular, poorly\\ndocumented, under-resourced, minority, or under-\\ndigitized due to their scarce resources. Much of the\\ndata and documentation for these languages remain\\nunpublished, exist only in print, or are extremely\\nlimited. Consequently, accessing and utilizing raw\\ntext in an extremely low-resource language is chal-\\nlenging.\\nA.2 Language description\\nTable 4 provides information on the languages of\\ninterest, including details such as scripts, number of\\nspeakers, data size, and geographical distributions.\\nA.3 Languages and their characteristics\\nOur primary languages of interest are Angika, Bho-\\njpuri, Hindi, and Magahi, spoken in the Indian\\nstates of Bihar, Jharkhand, West Bengal, and some\\nparts of Nepal. Table 4 provides an overview of\\nthe selected languages. These selected languages,\\nrepresenting the Bihari language group, belong\\nto the Indo-Aryan language family (Collin, 2010).\\nThey all use the Devanagari script, having transi-\\ntioned from their individual writing scripts. All\\nof these languages demonstrate tonal character-\\nistics. As far as morphosyntax is concerned, a\\nseparate morpheme marks the plural instead of\\na suffix. All the mentioned languages feature a\\nbound morpheme acting as a classifier. In addi-\\ntion to singular and plural forms, Angika, Magahi,\\nand Bhojpuri contain equal, honorific, and non-\\nhonorific variations of second-person personal pro-\\nnouns. Derived adjectives are present in all lan-\\nguages. While Angika and Bhojpuri offer all three\\ntenses, Bhojpuri lacks morphological availability\\nfor the present tense. Angika exhibits simple or',\n",
              " 'Language Scripts No. of No. of Geographical\\nspeakers sentences distribution\\nAngika Devanagari 15M 708 Bihar, Jharkhand, West Bengal,Nepal\\nBhojpuri Devanagari 52M 708 Fiji, Bihar, Uttar Pradesh, Jharkhand,\\nChhattisgarh, Madhya Pradesh\\nMagahi Devanagari 14M 708 Bihar, Jharkhand, Nepal\\nTable 4: Data statistics showing language, writing script, number of native speakers, geographical distribution, and\\nnumber of sentences in our POS-tagging corpus across all four languages.\\ncontinuous tenses, and Magahi distinguishes be-\\ntween future and non-future tenses. The word order\\nfor all languages is Subject-Object-Verb (SOV).\\nCloseness to Hindi Hindi, Angika, Bhojpuri, and\\nMagahi share similar word order (SOV) and scripts\\nand belong to the Indo-Aryan family. They dif-\\nfer significantly in number, gender, tense, aspect,\\nmood, and case markers. For example, Hindi verbs\\nundergo extensive conjugation for person, num-\\nber, tense, and mood. In contrast, Angika and Ma-\\ngahi verbs follow distinct conjugational patterns,\\nleading to variations in agreement and verb forms\\nwithin sentences. Furthermore, the structure and\\nplacement of relative clauses differ between the two\\nlanguages. Despite all languages utilizing the De-\\nvanagari script, identical words may convey differ-\\nent meanings. For example, consider the Hindi sen-\\ntence “hamen bachaav ke baare mein kuchh bhee\\nparavaah nahin thee” (We did not care about saving\\nanything), which translates to Angika as “hammae\\nsinee ka kuchchhoo bachaay ro baare mein par-\\navaay nai chelai.” Here, the pronoun \"hamen\" (we)\\nin Hindi is expressed in Angika as \"hammae si-\\nnee ka\" (we). While in Hindi, it represents the\\nfirst-person singular form, in Angika, it denotes the\\nfirst-person plural form.\\nA.4 Quality control\\nTo assess the quality of the POS annotation task,\\nwe abstained from computing automatic inter-\\nannotator agreement metrics like Fleiss Kappa\\n(Fleiss, 1971). For sequence labelling datasets,\\ndataset creators did not compute agreement as it\\nrelied on token level span (Klie et al., 2023). Brand-\\nsen et al. (2020) claims that per-token agreement\\nin sequence labelling presents challenges, as anno-\\ntators label sequences instead of individual tokens,\\ndiluting the measure’s ability to capture the essence\\nof the task. Additionally, nouns dominate the la-\\nbelled data, creating an imbalanced dataset that\\ncould skew results. Considering these challenges,we opted for in-person discussions with annota-\\ntors to reach a consensus on correct annotations for\\neach word in the sentence. The manual, in-person\\napproaches to quality control are suitable and pro-\\nvide reassurance regarding the high quality of the\\nannotation (Cardenas et al., 2019). In cases of dis-\\nagreement, annotators collaborated with language\\nexperts to resolve the issue. For Hindi, sentence-\\nlevel annotation achieved over 90% agreement; for\\nAngika, Bhojpuri, and Magahi, sentence-level an-\\nnotation reached over 88% agreement. After qual-\\nity control, our corpus is the most extensive parallel\\ncorpus for Hindi, Angika, Bhojpuri, and Magahi\\nwithin the UD dataset, where test sets typically\\ninvolve 300 sentences.\\nA.5 Experiment setup\\nFor fine-tuning the PLMs, we employed a batch\\nsize of 16, a learning rate of 2e-5, and a weight\\ndecay of 0.01, and we conducted the experiments\\nover 10 epochs. The computations were performed\\nusing Nvidia A100 GPU.',\n",
              " 'Tags Hindi Angika Magahi Bhojpuri A VG\\nADJ 0.89 0.68 0.74 0.76 0.73\\nADP 0.96 0.82 0.94 0.94 0.90\\nADV 0.95 0.36 0.51 0.48 0.45\\nAUX 0.96 0.78 0.84 0.81 0.81\\nCCONJ 0.93 0.70 0.87 0.88 0.82\\nDET 0.78 0.43 0.48 0.55 0.49\\nINTJ\\nNOUN 0.93 0.83 0.85 0.87 0.85\\nNUM 0.9 0.75 0.69 0.74 0.73\\nPART 0.91 0.47 0.79 0.75 0.67\\nPRON 0.93 0.69 0.7 0.63 0.67\\nPROPN 0.85 0.5 0.57 0.49 0.52\\nPUNCT 0.98 0.99 0.98 1.00 0.99\\nSCONJ 0.83 0.63 0.68 0.63 0.65\\nSYM 1.00 1.00 1.00 1.00 1.00\\nVERB 0.95 0.71 0.75 0.82 0.76\\nX\\n-\\nTable 5: F1-scores for POS tags across all languages. The average is calculated over Angika, Magahi, and Bhojpuri\\nonly. All scores are for MuRIL in the zero-shot setting, as it outperforms RemBERT and XLM-R-Large in this\\nscenario.\\nTags Hindi Angika Magahi Bhojpuri A VG\\nADJ 0.92 0.73 0.74 0.78 0.75\\nADP 0.98 0.82 0.94 0.94 0.90\\nADV 0.96 0.40 0.45 0.48 0.44\\nAUX 0.98 0.80 0.86 0.84 0.83\\nCCONJ 0.96 0.92 0.88 0.89 0.90\\nDET 0.8 0.44 0.47 0.59 0.50\\nINTJ\\nNOUN 0.96 0.87 0.86 0.89 0.87\\nNUM 0.91 0.76 0.68 0.69 0.71\\nPART 0.90 0.47 0.76 0.72 0.65\\nPRON 0.96 0.76 0.8 0.76 0.77\\nPROPN 0.88 0.64 0.65 0.61 0.63\\nPUNCT 0.99 0.99 1.00 1.00 1.00\\nSCONJ 0.85 0.53 0.71 0.70 0.65\\nSYM 1.00 1.00 1.00 1.00 1.00\\nVERB 0.97 0.78 0.81 0.86 0.80\\nX\\n-\\nTable 6: F1-scores for POS tags across all languages. The average is calculated over Angika, Magahi, and Bhojpuri\\nonly. All scores are for MuRIL in the look-back setting.',\n",
              " 'Tags Hindi Angika Magahi Bhojpuri A VG\\nADJ 0.95 0.73 0.74 0.76 0.74\\nADP 0.98 0.82 0.94 0.94 0.90\\nADV 0.95 0.36 0.49 0.48 0.44\\nAUX 0.98 0.78 0.84 0.82 0.81\\nCCONJ 0.97 0.89 0.87 0.88 0.88\\nDET 0.81 0.43 0.58 0.55 0.52\\nINTJ\\nNOUN 0.95 0.83 0.85 0.87 0.85\\nNUM 0.92 0.75 0.69 0.82 0.75\\nPART 0.88 0.44 0.79 0.74 0.66\\nPRON 0.96 0.78 0.7 0.75 0.74\\nPROPN 0.87 0.64 0.57 0.59 0.60\\nPUNCT 0.98 0.99 0.98 1.00 0.99\\nSCONJ 0.83 0.63 0.68 0.63 0.65\\nSYM 1.00 1.00 1.00 1.00 1.00\\nVERB 0.97 0.74 0.75 0.82 0.76\\nX\\n-\\nTable 7: F1-scores for POS tags across all languages. The average is calculated over Angika, Magahi, and Bhojpuri\\nonly. All scores are for MuRIL in the look-back-with-score setting.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "- There are 10 element in the list $documents$, each representing a page."
      ],
      "metadata": {
        "id": "KhljaqK4L9S_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "### Document Processing for Vector Databases\n",
        "\n",
        "- Every page is treated as a separate document, ready for embedding (vectorization) and storage in a vector database. However, varying page lengths can significantly affect search and retrieval quality.\n",
        "\n",
        "- Since LLMs have a limited context window (token limit), we first concatenate all pages into a single long document, then split it into smaller, roughly equal-sized chunks. Each chunk is embedded and inserted into the vector database.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "Unqh5WNWOsuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PDFMinerLoader\n",
        "\n",
        "loader = PDFMinerLoader(PATH)\n",
        "pdf_content = loader.load()"
      ],
      "metadata": {
        "id": "yesRlew2LvIh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QosidjB2Mfza",
        "outputId": "21940257-0227-44aa-852b-d2bae779a7f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/paper-1.pdf'}, page_content='Part-of-speech Tagging for Extremely Low-resource Indian Languages\\n\\nSanjeev Kumar, Preethi Jyothi, Pushpak Bhattacharyya\\nComputer Science and Engineering, IIT Bombay, India\\n{sanjeev, pjyothi, pb}@cse.iitb.ac.in\\n\\nAbstract\\n\\nModern natural language processing (NLP) sys-\\ntems thrive when given access to large datasets.\\nHowever, a large fraction of the world’s lan-\\nguages are not privy to such benefits due to\\nsparse documentation and inadequate digital\\nrepresentation. This is especially true for In-\\ndian regional languages. As a first step towards\\nexpanding the reach of NLP technologies to\\nextremely low-resource Indian languages, we\\npresent a new parallel part-of-speech (POS)\\nevaluation dataset for Angika, Magahi, Bho-\\njpuri and Hindi. Angika, Magahi, Bhojpuri,\\nalong with the more well-known Hindi, are all\\nlanguages spoken in the Indian states of Bi-\\nhar, Jharkhand and West Bengal. Ours is no-\\ntably the first NLP resource, even for a shallow\\nNLP task like POS-tagging, for Angika. We\\nestablish POS-tagging baselines using state-of-\\nthe-art multilingual pretrained language models\\n(PLMs) finetuned on Hindi data, and show zero-\\nshot evaluations on the other three languages.\\nWhile all four languages use the same Devana-\\ngari script, pretrained tokenizers underperform\\nin zero-shot on the three languages. We pro-\\npose a simple look-back fix to address the tok-\\nenization challenge yielding F1-score improve-\\nments of up to 8% on Angika, and show how\\nit comes very close to an oracle setting when\\nthe underlying Hindi word is known (and can\\nbe accurately tokenized).\\n\\n1\\n\\nIntroduction\\n\\nIndia is a multilingual country with more than 1369\\nlanguages and five main language families (Office\\nof the Registrar General Census Commissioner,\\n2022). While the Indian constitution officially rec-\\nognizes 22 languages, numerous others face a bat-\\ntle for survival. English is spoken by only roughly\\n10% of the population (Office of the Registrar Gen-\\neral Census Commissioner, 2022) in India; the\\nmajority prefers their diverse regional languages\\ndeeply rooted in cultural heritage. Building tech-\\nnologies for regional Indian languages is important\\n\\nto ensure inclusivity across user groups and em-\\npower people for everyday interactions.\\n\\nWhile there has been progress towards promot-\\ning multilinguality and linguistic diversity across\\nIndian languages with tools like IndicNLPSuite\\n(Kakwani et al., 2020) and multilingual corpora\\nsuch as Common Crawl Oscar Corpus (Wenzek\\net al., 2019), PMIndia (Haddow and Kirefu, 2020),\\nand Samanantar (Ramesh et al., 2021), there is\\nalmost no representation of low-resource Indian\\nlanguages like Angika in these resources.\\n\\nIn this work, we focus on three very low-\\nresource Indian languages Angika, Magahi and\\nBhojpuri and create parallel POS-tagging evalu-\\nation corpora for these three languages, consis-\\ntent with Universal Dependencies (UD) guide-\\nlines. These are the first UD-compliant datasets\\nfor Angika and Magahi. We also create a Hindi\\nPOS-tagging dataset that is parallel to the data\\nin the three languages. Hindi is the closest high-\\nresource Indian language that is related to Bhojpuri,\\nAngika and Magahi. This allows us to carefully\\nexamine the cross-lingual performance gap com-\\npared to Hindi, whether transfer from a related\\nhigh-resource language like Hindi is possible, and\\nchallenges related to tokenization that affect zero-\\nshot performance on the low-resource languages.\\nWe propose a simple look-back scheme that cir-\\ncumvents most errors that stem due to suboptimal\\ntokenization for the three low-resource languages.\\nTo encourage further work on these languages, we\\npublicly release our new dataset and code to repro-\\nduce all our experiments 1.\\n\\n2 Related Work\\n\\nShallow NLP tasks such as POS tagging for low-\\nresource languages have been studied fairly exten-\\nsively in prior work, many of which have explored\\ncross-lingual transfer learning techniques. Fang\\n\\n1https://www.github.com/snjev310/acl-24-pos\\n\\n\\x0cand Cohn (2016) achieve successful POS tagging,\\nespecially in low-resource languages (like Mala-\\ngasy and Kinyarwanda), by combining word align-\\nment with gold-standard data. Kim et al. (2017) im-\\nplemented a BiLSTM model that utilizes word and\\ncharacter embeddings to transfer knowledge with-\\nout relying on parallel corpora. Another approach\\nby Huck et al. (2019) introduces zero-shot tag-\\nging, by projecting annotations from a related high-\\nresource language, such as Russian for Ukrainian.\\nMore recently, Dione et al. (2023) demonstrated\\nsignificant improvements in POS tagging by using\\nmultilingual pretrained LMs trained on typologi-\\ncally diverse African languages. Recent work has\\nalso employed modular learning (Lin et al., 2019;\\nArtetxe et al., 2020; Pfeiffer et al., 2020; Min et al.,\\n2023) techniques with multilingual pretrained lan-\\nguage models (PLMs) to enable effective cross-\\nlingual transfer to low-resource languages. Prior\\nwork on POS tagging for various low-resource\\nIndo-Aryan languages has mainly utilized classical\\nNLP techniques and do not leverage PLMs. For\\nexample, Saharia et al. (2009) developed a POS\\ntagger for Assamese and Basit and Kumar (2019)\\nfor Awadhi, and both works used an HMM model.\\nAmong the four languages of interest, other than\\nHindi, there is an existing UD-compliant POS-\\ntagging evaluation dataset for Bhojpuri (Ojha and\\nZeman, 2020). However, it only has 268 sentences.\\nOverall, there is a strong need for NLP datasets\\ncovering extremely low-resource Indian languages\\n(such as Angika). We think it is also useful to de-\\nvelop parallel datasets along with relatively higher-\\nresource languages (such as Hindi) that share com-\\nmon geographical boundaries, word order, script,\\nand language family. This helps understand how\\ncross-lingual transfer can be more effectively uti-\\nlized from high-resource languages.\\n\\n3 Data Collection and Annotation\\n\\nWe created a parallel corpus comprising 708 evalu-\\nation sentences each for Hindi, Angika, Bhojpuri,\\nand Magahi. We used some Hindi monolingual\\ndata from Kunchukuttan et al. (2018) and trans-\\nlated into Angika, Magahi, and Bhojpuri. Some\\nAngika monolingual data was extracted from the\\nwebonary2 Angika dictionary and translated into\\nHindi and the other two languages. The UD dataset\\nprimarily draws data from the news domain, re-\\nsulting in a higher frequency of named entities\\n\\n2https://www.webonary.org/angika/\\n\\nbelonging to the noun class. To improve diversity,\\nwe incorporated sentences of daily conversations\\nand regional stories. Additionally, we included a\\nfew frequently used sentences by native speakers.\\nIssues in the webonary Angika dictionary such as\\nword misspellings and missing sentences were man-\\nually addressed. Languages were translated by re-\\nspective language annotators and verified by native\\nspeakers. Table 4 in Appendix A.2 provides more\\ndetails for all four languages and Appendix A.4 pro-\\nvides more details about our measures for quality\\ncontrol in the annotations.\\n\\n4 Experiments and Results\\n\\nWe provide POS tagging baselines using multi-\\nlingual PLMs in a zero-shot setting. We fine-\\ntune an Indic-specific multilingual PLM (MURIL\\n(Khanuja et al., 2021)) on Hindi UD POS-tagging\\ndata consisting of 13K sentences. We refer to this\\nmodel as “Hindi FT\". We also fine-tuned on other\\nmassively multilingual PLMs, XLM-R-large (Con-\\nneau et al., 2020) and RemBERT (Chung et al.,\\n2020)), as a comparison to MURIL. All three PLMs\\nhave been pretrained on around 100-110 languages,\\nwith the exception of MuRIL, which is exclusively\\npretrained on 12 major Indic languages. How-\\never, none of these models are pretrained on any\\nof the low-resource languages that we explore in\\nthis work. More details regarding the experimental\\nsetup can be found in Appendix A.5.\\n\\n4.1 Baseline Models\\n\\nTable 1 presents the zero-shot POS tagging results\\nfor all three low-resource languages (under “Hindi\\nFT\"). MuRIL has a slight advantage over XLM-R\\nand RemBERT in the zero-shot setting. MuRIL is\\nsignificantly smaller in size, compared to XLM-R-\\nlarge and RemBERT. However, it performs best on\\nthe low-resource languages possibly by benefiting\\nfrom its Indic-only pretraining, as opposed to the\\nother PLMs that will have language interference\\nfrom many non-Indic languages.\\n\\nWe also evaluate MuRIL on publicly available\\nUD Hindi test data to validate our model setup. On\\nthe UD Hindi test data, MuRIL achieves an F1-\\nscore of 0.96, which is comparable to the F1-score\\nwe obtained on our Hindi evaluation set (0.93).\\nThis validates our model setup and acts as a sanity\\ncheck for the quality of our Hindi data.\\n\\n\\x0cHindi FT\\n\\nLook-back\\n\\nHindi\\nR\\n0.94\\n0.93\\n0.94\\n0.94\\n0.94\\n0.95\\n0.94\\n0.94\\n0.95\\n0.94\\n0.95\\n0.95\\n\\nF1\\n0.93\\n0.93\\n0.94\\n0.93\\n0.94\\n0.95\\n0.94\\n0.94\\n0.95\\n0.94\\n0.95\\n0.95\\n\\nP\\n0.93\\n0.93\\n0.93\\n0.93\\n0.95\\n0.95\\n0.94\\n0.95\\n0.95\\n0.95\\n0.95\\n0.95\\n\\nAngika\\nR\\n0.72\\n0.69\\n0.71\\n0.71\\n0.77\\n0.73\\n0.73\\n0.74\\n0.76\\n0.74\\n0.75\\n0.75\\n\\nF1\\n0.69\\n0.69\\n0.69\\n0.69\\n0.77\\n0.74\\n0.74\\n0.75\\n0.77\\n0.75\\n0.76\\n0.76\\n\\nP\\n0.66\\n0.68\\n0.67\\n0.67\\n0.80\\n0.78\\n0.79\\n0.79\\n0.80\\n0.79\\n0.80\\n0.80\\n\\nMagahi\\nR\\n0.78\\n0.74\\n0.77\\n0.76\\n0.82\\n0.76\\n0.79\\n0.79\\n0.81\\n0.80\\n0.81\\n0.81\\n\\nP\\n0.74\\n0.73\\n0.75\\n0.74\\n0.84\\n0.81\\n0.82\\n0.82\\n0.83\\n0.83\\n0.83\\n0.83\\n\\nF1\\n0.76\\n0.74\\n0.76\\n0.75\\n0.83\\n0.77\\n0.80\\n0.80\\n0.82\\n0.80\\n0.81\\n0.81\\n\\nBhojpuri\\nR\\n0.80\\n0.77\\n0.77\\n0.77\\n0.83\\n0.75\\n0.78\\n0.79\\n0.82\\n0.80\\n0.81\\n0.81\\n\\nF1\\n0.79\\n0.76\\n0.76\\n0.77\\n0.84\\n0.75\\n0.79\\n0.79\\n0.83\\n0.80\\n0.81\\n0.81\\n\\nP\\n0.78\\n0.76\\n0.76\\n0.76\\n0.85\\n0.80\\n0.82\\n0.83\\n0.85\\n0.83\\n0.84\\n0.84\\n\\nMuRIL\\nXLM-R large\\nRemBERT\\nAVG\\nMuRIL\\nXLM-R large\\nRemBERT\\nAVG\\nMuRIL\\n\\nRemBERT\\nAVG\\n\\nLook-back\\nwith score XLM-R large\\n\\nTable 1: POS tagging Precision (P), Recall (R), and F1-score (F1) of three PLMs evaluated on our parallel dataset\\nusing zero-shot, look-back, and look-back-with-score methods. Results range from 0 to 1 and are averaged across\\nfive random seeds.\\n\\n4.2 Tokenization Inconsistencies\\n\\nIn the case of extremely low-resource languages,\\na pretrained tokenizer tends to break words into\\nmultiple sub-word tokens. In our experiments, we\\npredict POS tags for each token. Thus, sub-optimal\\ntokenization can result in poor quality predictions.\\nFor extremely low-resource languages, words may\\nbe split all the way down into individual characters\\nwhich makes the POS predictions even noisier. In\\nSection 4.3, we propose a simple look-back scheme\\nto alleviate some of the issues that stem from poor\\ntokenization. In Section 4.4, we analyze how much\\nwe could make up for tokenization challenges in\\nan oracle setting if we had access to parallel data\\nin Hindi.\\n\\n4.3\\n\\nInvestigating the impact of sub-word\\n\\nWhen a tokenizer breaks down words into sub-\\nwords, these sub-words can get different tags. Poor\\ntokenization that leads to over-fragmentation ex-\\nacerbates this problem. In our quantitative dataset\\nanalysis, we observed that in Angika, Magahi and\\nBhojpuri around 45% of words were split into 2, 3,\\nand 4 sub-word tokens. To address this challenge,\\nwe introduce two simple techniques: look-back and\\nlook-back-with-score.\\n\\nLook-back. We substitute the POS tags corre-\\nsponding to all the tokens in a word with the POS\\ntag of the first token. This approach was chosen\\nbecause the first split token closely relates to the\\nword in a higher-resource language, preserving\\nmeaning and POS tags. For example, an Angika\\nword “dEkhAibae\" (will see), splits into “dEkh”\\nand “ibae” here, the word “dEkh” (see) is related\\nto Hindi. The results of this look-back approach\\n\\nare shown in Table 1. We find significant improve-\\nments in performance across all three low-resource\\nlanguages, most notably for Angika.\\n\\nIf a word W is split\\n\\nLook-back-with-score. Each token produces\\nlogit values corresponding to the tag distribu-\\ninto n sub-\\ntions.\\nwords (w1, w2, . . . , wn) with corresponding logits\\n(l1, l2, . . . , ln), we find the sub-word token with the\\nmaximum logit score and retrieve its corresponding\\nPOS label. We replace the POS tags of all other\\nsub-word tokens in that word with the POS tag of\\nthe maximum-scoring token.\\n\\nWhen comparing look-back and look-back-with-\\nscore methods in Table 1,\\nthe results suggest\\nthat, on average, look-back-with-score outperforms\\nlook-back (+1% increase in F1-score across all\\nlanguages and all models). Our initial observa-\\ntions indicate that tokenizers generally split words\\ninto tokens that are seen in the vocabulary of high-\\nresource languages, and thus replacing the tag of\\nsubsequent tokens with the tag of the first token\\nis a reasonable strategy to mitigate token-level in-\\nconsistencies. However, the “look-back with score”\\napproach utilizes information from tokens within\\na word, and this turns out to offer a small but\\nconsistent advantage across all three languages.\\nThe look-back-with-score approach is less effective\\nfor MuRIL compared to look-back. This may be\\nbecause MuRIL, primarily trained on Indian lan-\\nguages, aligns initial split tokens more closely with\\nHindi, resulting in a higher confidence level for the\\nfirst token than for other split tokens.\\n\\n4.4 Using Hindi Parallel Data\\n\\nHere, we assess the effectiveness of having access\\nto a parallel corpus of a relatively higher resource\\n\\n\\x0cHindi FT\\n\\nOracle\\n\\nNon-oracle\\n\\nMuRIL\\nXLM-R large\\nRemBERT\\nAVG\\nMuRIL\\nXLM-R large\\nRemBERT\\nAVG\\nMuRIL\\nXLM-R large\\nRemBERT\\nAVG\\n\\nHindi\\nR\\n0.94\\n0.93\\n0.94\\n0.94\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n\\nF1\\n0.93\\n0.93\\n0.94\\n0.94\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n\\nP\\n0.93\\n0.93\\n0.93\\n0.93\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n\\nAngika\\nR\\n0.72\\n0.69\\n0.71\\n0.71\\n0.78\\n0.76\\n0.75\\n0.76\\n0.64\\n0.51\\n0.50\\n0.55\\n\\nP\\n0.66\\n0.68\\n0.67\\n0.67\\n0.81\\n0.80\\n0.80\\n0.80\\n0.70\\n0.57\\n0.58\\n0.62\\n\\nF1\\n0.69\\n0.69\\n0.69\\n0.69\\n0.79\\n0.76\\n0.76\\n0.77\\n0.64\\n0.49\\n0.53\\n0.55\\n\\nMagahi\\nR\\n0.78\\n0.74\\n0.77\\n0.76\\n0.84\\n0.79\\n0.83\\n0.82\\n0.68\\n0.60\\n0.59\\n0.63\\n\\nF1\\n0.76\\n0.74\\n0.76\\n0.75\\n0.84\\n0.79\\n0.83\\n0.82\\n0.69\\n0.57\\n0.62\\n0.63\\n\\nP\\n0.74\\n0.73\\n0.75\\n0.74\\n0.85\\n0.82\\n0.85\\n0.84\\n0.73\\n0.64\\n0.65\\n0.67\\n\\nBhojpuri\\nR\\n0.80\\n0.77\\n0.77\\n0.77\\n0.85\\n0.80\\n0.84\\n0.83\\n0.71\\n0.63\\n0.61\\n0.65\\n\\nP\\n0.78\\n0.76\\n0.76\\n0.76\\n0.87\\n0.83\\n0.85\\n0.85\\n0.75\\n0.67\\n0.66\\n0.69\\n\\nF1\\n0.79\\n0.76\\n0.76\\n0.77\\n0.85\\n0.80\\n0.84\\n0.83\\n0.72\\n0.60\\n0.63\\n0.65\\n\\nTable 2: POS tagging Precision (P), Recall (R), and F1-scores (F1) of three PLMs evaluated on our parallel data\\nusing zero-shot (‘Hindi FT’), oracle and non-oracle methods. Results range from 0 to 1 and are averaged across five\\nrandom seeds.\\n\\nlanguage, which shares the script, word order, and\\ngeographical boundaries and can assist in POS tag\\npredictions for extremely low-resource languages.\\nFor this analysis, we have introduced two methods:\\nthe oracle setting, where we have oracle knowledge\\nof incorrectly predicted POS tags, and the non-\\noracle setting, where we lack any prior knowledge\\nof incorrectly predicted POS tags.\\n\\nOracle setting. We compare our model’s predic-\\ntions for Angika, Magahi and Bhojpuri with the\\nground-truth POS tag sequences. For mismatches,\\nwe utilize the parallel corpus in Hindi to identify\\nthe corresponding Hindi token and the most fre-\\nquently occurring tag for the aligned Hindi token.\\nThis tag replaces our model predictions in the other\\nthree low-resource languages.\\n\\nNon-oracle setting. We substitute the predicted\\ntags of a token with the original tags from the par-\\nallel corpus. This involves choosing the tag with\\nthe highest frequency for an aligned Hindi token in\\nthe parallel corpus. In this setting, we achieve F1-\\nscores of 0.67, 0.63, and 0.65 for Angika, Magahi,\\nand Bhojpuri, respectively, which is significantly\\nlower than the scores obtained in the zero-shot and\\noracle settings.\\n\\nTable 2 presents the results of both approaches.\\nWhen comparing the oracle and non-oracle results\\nwith the zero-shot approach, we observe that hav-\\ning access to a parallel corpus in a comparatively\\nhigher-resource language improves the overall tag-\\nging performance, primarily when focusing on\\nwrongly predicted tags. However, since we do not\\nhave apriori information of whether our predicted\\ntag is correct or not, the non-oracle approach of\\nalways replacing it with the Hindi token’s most\\n\\nfrequent POS tag results in a notable decline in\\nperformance.\\n\\n4.5 Tag-level Analysis\\n\\nTable 1 shows significant improvements in perfor-\\nmance using look-back-with-score over the zero-\\nshot baseline. These methods provide notable\\nperformance gains for tags like pronouns, proper\\nnouns, conjunctions, adjectives, and numbers. We\\nillustrate how a simple strategy like look-back sig-\\nnificantly helps with an example. Consider the\\nAngika sentence “HamMe aArU tOI miLika duGo\\naAma kHaIlIye” (Translation: You and I ate two\\nmangoes together). While a pretrained tokenizer\\ncorrectly identifies “hamMe” as two pronouns in\\nAngika, it might misrecognize their individual tags\\n(“ham” as pronoun, “Me” as adposition). The look-\\nback method leverages contextual information to\\nrectify these errors by correctly predicting both to-\\nkens as pronouns. This results in an improvement\\nover the zero-shot setting. Similar morphological\\nstructures are observed with numerals like “duGo”\\n(meaning “two”). All these languages employ a\\nclassifier as a bound morpheme, with “Go” as the\\nspecific marker for numbers. A broader analysis\\nof the linguistic properties causing errors in the\\nzero-shot setting is discussed in 4.6.\\n\\n4.6 Error Analysis\\n\\nTable 3 shows tag-wise F1-scores for different lan-\\nguages using MuRIL in zero-shot and look-back-\\nwith-score settings. Subordinate conjunctions, pro-\\nnouns, proper nouns, particles, determiners, and\\nadverbs exhibit lower F1-scores compared to other\\ntags. Adjectives and numbers also show lower\\nscores than Hindi and the total occurrences of tags\\n\\n\\x0cTags\\nADJ\\nADP\\nADV\\nAUX\\nCCONJ\\nDET\\nNOUN\\nNUM\\nPART\\nPRON\\nPROPN\\nPUNCT\\nSCONJ\\nSYM\\nVERB\\n\\nHindi FT\\nHindi Angika Magahi\\n0.89\\n0.96\\n0.95\\n0.96\\n0.93\\n0.8\\n0.93\\n0.9\\n0.91\\n0.93\\n0.85\\n0.98\\n0.83\\n1.00\\n0.95\\n\\n0.68\\n0.82\\n0.36\\n0.78\\n0.70\\n0.44\\n0.83\\n0.75\\n0.47\\n0.69\\n0.5\\n0.99\\n0.63\\n1.00\\n0.71\\n\\n0.74\\n0.94\\n0.51\\n0.84\\n0.87\\n0.47\\n0.85\\n0.69\\n0.79\\n0.7\\n0.57\\n0.98\\n0.68\\n1.00\\n0.75\\n\\nLook-back-with-score\\n\\nBhojpuri AVG Hindi Angika Magahi Bhojpuri AVG\\n0.74\\n0.73\\n0.90\\n0.82\\n0.44\\n0.36\\n0.81\\n0.78\\n0.88\\n0.89\\n0.52\\n0.43\\n0.85\\n0.83\\n0.75\\n0.75\\n0.66\\n0.44\\n0.74\\n0.78\\n0.60\\n0.64\\n0.99\\n0.99\\n0.65\\n0.63\\n1.00\\n1.00\\n0.76\\n0.74\\n\\n0.76\\n0.94\\n0.48\\n0.81\\n0.88\\n0.59\\n0.87\\n0.74\\n0.75\\n0.63\\n0.49\\n1.00\\n0.63\\n1.00\\n0.82\\n\\n0.95\\n0.98\\n0.95\\n0.98\\n0.97\\n0.81\\n0.95\\n0.92\\n0.88\\n0.96\\n0.87\\n0.98\\n0.83\\n1.00\\n0.97\\n\\n0.74\\n0.94\\n0.49\\n0.84\\n0.87\\n0.58\\n0.85\\n0.69\\n0.79\\n0.7\\n0.57\\n0.98\\n0.68\\n1.00\\n0.75\\n\\n0.76\\n0.94\\n0.48\\n0.82\\n0.88\\n0.55\\n0.87\\n0.82\\n0.74\\n0.75\\n0.59\\n1.00\\n0.63\\n1.00\\n0.82\\n\\n0.73\\n0.90\\n0.45\\n0.81\\n0.82\\n0.50\\n0.85\\n0.73\\n0.67\\n0.67\\n0.52\\n0.99\\n0.65\\n1.00\\n0.76\\n\\nTable 3: Tag-wise F1-scores using MuRIL for POS tags across all languages for the zero-shot baseline (‘Hindi FT’)\\nand ‘look-back-with-score’ method. Average (AVG) is calculated using Angika, Magahi, and Bhojpuri scores.\\n\\nin the dataset, particularly when compared to par-\\nticles and determiners. These disparities can be\\nattributed to complexities in word formations and\\na few other linguistic nuances detailed below.\\n\\nAngika: Mohane kitaB padhalkae.\\nBhojpuri: Mohane kitaB padhlAs.\\nMaghai: Mohane kitaB padalAi.\\nEnglish Translation: Mohan read the book.\\n\\nTag confusion between subordinate conjunction,\\nadposition, and pronoun.\\nIn Angika, Magahi\\nand Bhojpuri, pronouns, adpositions and subordi-\\nnate conjunctions are written similarly. For e.g.:\\nHindi: kyA tum kal aAogI?\\nAngika: kI toI kaAl aAiybae?\\nBhojpuri: kA tu kal aAiyebu?\\nMagahi: kA tu kal aAibhe?\\nEnglish: Will you come tomorrow?\\nIn this example, kyA, kI, and kA are pronouns,\\nbut kI and kA are written as Hindi adposition and\\nsubordinate conjunctions.\\n\\nClassifiers. Angika, Bhojpuri, and Magahi lan-\\nguages often make use of classifier markers (Tho,\\nGo) to accompany numbers (e.g., Ek (one) and dU\\n(two)). Classifier markers in these languages are:\\nTo, Te, go, Ke, etc. Hindi does not exhibit this\\nproperty. For e.g.:\\nHindi: Ek sajJan.\\nAngika: EkTa SajJanA.\\nBhojpuri: EGo sajJanA.\\nMagahi: EaGo sajJanA.\\nEnglish Translation: One gentleman.\\n\\nNon-ergative construction. Hindi is an ergative\\nlanguage, while Angika, Bhojpuri, and Magahi are\\nnon-ergative. In Hindi, when the subject is desig-\\nnated with [ne] (oblique case), the transitive verb\\nagrees with the object in terms of person, number,\\nand gender. For e.g.:\\nHindi: Mohan ne kitaB padi.\\n\\n5 Conclusion\\n\\nThis paper introduces a UD-compliant parallel POS\\ntag dataset for three extremely low-resource Indian\\nlanguages: Angika, Magahi and Bhojpuri. This\\nwork contributes one of the first NLP resources for\\nthese languages and is a first step towards address-\\ning their under-representation in the digital land-\\nscape. We provide state-of-the-art POS baselines\\nby fine-tuning multilingual PLMs with Hindi data.\\nWe find that pretrained Indic tokenizers adversely\\naffect cross-lingual transfer to Angika, Magahi and\\nBhojpuri which we largely address with a simple\\nlook-back scheme.\\n\\nAcknowledgements\\n\\nThe first author would like to gratefully acknowl-\\nedge a Ph.D. grant from the TCS Research Foun-\\ndation to support his research on extremely low-\\nresource Indian languages. We would like to thank\\nthe anonymous reviewers for their helpful com-\\nments.\\n\\nLimitations\\n\\n1. While we cover three low-resource languages,\\nmany others like Bajjika, Surajpuri, and\\nMaithili, which share geographical boundaries\\nwith our languages of interest, have not been\\nincluded.\\n\\n\\x0c2. Due to the smaller size of our dataset com-\\npared to larger POS datasets, we do not have a\\nlot of diversity across domains. We note that\\nthe POS dataset and the observations in this\\nwork may not be applicable to all domains,\\nsuch as speech transcripts or conversational\\ndata.\\n\\nEthics Statement\\n\\nWe would like to emphasize our commitment to\\nupholding ethical practices throughout this work.\\nWe aimed to ensure that human annotators received\\na fair compensation for their annotation efforts and\\nwas commensurate with the time and effort invested\\nin their work.\\n\\nReferences\\n\\nMikel Artetxe, Sebastian Ruder, and Dani Yogatama.\\n2020. On the cross-lingual transferability of mono-\\nlingual representations. In Proceedings of the 58th\\nAnnual Meeting of the Association for Computational\\nLinguistics, pages 4623–4637, Online. Association\\nfor Computational Linguistics.\\n\\nAbdul Basit and Ritesh Kumar. 2019. Towards a part-of-\\nspeech tagger for awadhi: Corpus and experiments.\\nIn (IJACSA) International Journal of Advanced Com-\\nputer Science and Applications.\\n\\nAlex Brandsen, Suzan Verberne, Milco Wansleeben,\\nand Karsten Lambers. 2020. Creating a dataset for\\nnamed entity recognition in the archaeology domain.\\nIn Proceedings of the Twelfth Language Resources\\nand Evaluation Conference, pages 4573–4577.\\n\\nRonald Cardenas, Ying Lin, Heng Ji, and Jonathan May.\\n2019. A grounded unsupervised universal part-of-\\nspeech tagger for low-resource languages. In Pro-\\nceedings of the 2019 Conference of the North Amer-\\nican Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume\\n1 (Long and Short Papers), pages 2428–2439, Min-\\nneapolis, Minnesota. Association for Computational\\nLinguistics.\\n\\nHyung Won Chung, Thibault Fevry, Henry Tsai, Melvin\\nJohnson, and Sebastian Ruder. 2020. Rethinking\\nembedding coupling in pre-trained language models.\\narXiv preprint arXiv:2010.12821.\\n\\nRichard Oliver Collin. 2010. Ethnologue. Ethnopolitics,\\n\\n9(3-4):425–432.\\n\\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\\nVishrav Chaudhary, Guillaume Wenzek, Francisco\\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\\n\\ncross-lingual representation learning at scale. In Pro-\\nceedings of the 58th Annual Meeting of the Asso-\\nciation for Computational Linguistics, pages 8440–\\n8451, Online. Association for Computational Lin-\\nguistics.\\n\\nCheikh M. Bamba Dione, David Ifeoluwa Adelani,\\nPeter Nabende, Jesujoba Alabi, Thapelo Sindane,\\nHappy Buzaaba, Shamsuddeen Hassan Muhammad,\\nChris Chinenye Emezue, Perez Ogayo, Anuoluwapo\\nAremu, Catherine Gitau, Derguene Mbaye, Jonathan\\nMukiibi, Blessing Sibanda, Bonaventure F. P. Dos-\\nsou, Andiswa Bukula, Rooweither Mabuya, Allah-\\nsera Auguste Tapo, Edwin Munkoh-Buabeng, Vic-\\ntoire Memdjokam Koagne, Fatoumata Ouoba Ka-\\nbore, Amelia Taylor, Godson Kalipe, Tebogo\\nMacucwa, Vukosi Marivate, Tajuddeen Gwadabe,\\nMboning Tchiaze Elvis, Ikechukwu Onyenwe, Gra-\\ntien Atindogbe, Tolulope Adelani, Idris Akinade,\\nOlanrewaju Samuel, Marien Nahimana, Théogène\\nMusabeyezu, Emile Niyomutabazi, Ester Chimhenga,\\nKudzai Gotosa, Patrick Mizha, Apelete Agbolo, Sey-\\ndou Traore, Chinedu Uchechukwu, Aliyu Yusuf,\\nMuhammad Abdullahi, and Dietrich Klakow. 2023.\\nMasakhaPOS: Part-of-speech tagging for typolog-\\nIn Proceedings\\nically diverse African languages.\\nof the 61st Annual Meeting of the Association for\\nComputational Linguistics (Volume 1: Long Papers),\\npages 10883–10900, Toronto, Canada. Association\\nfor Computational Linguistics.\\n\\nMeng Fang and Trevor Cohn. 2016. Learning when\\nto trust distant supervision: An application to low-\\nresource POS tagging using cross-lingual projection.\\nIn Proceedings of the 20th SIGNLL Conference on\\nComputational Natural Language Learning, pages\\n178–186, Berlin, Germany. Association for Compu-\\ntational Linguistics.\\n\\nJoseph L Fleiss. 1971. Measuring nominal scale agree-\\nment among many raters. Psychological bulletin,\\n76(5):378.\\n\\nBarry Haddow and Faheem Kirefu. 2020. Pmindia–a\\ncollection of parallel corpora of languages of india.\\narXiv preprint arXiv:2001.09907.\\n\\nMatthias Huck, Diana Dutka, and Alexander Fraser.\\n2019. Cross-lingual annotation projection is effective\\nfor neural part-of-speech tagging. In Proceedings of\\nthe Sixth Workshop on NLP for Similar Languages,\\nVarieties and Dialects, pages 223–233.\\n\\nDivyanshu Kakwani, Anoop Kunchukuttan, Satish\\nGolla, NC Gokul, Avik Bhattacharyya, Mitesh M\\nKhapra, and Pratyush Kumar. 2020. Indicnlpsuite:\\nMonolingual corpora, evaluation benchmarks and\\npre-trained multilingual language models for indian\\nlanguages. In Findings of the Association for Com-\\nputational Linguistics: EMNLP 2020, pages 4948–\\n4961.\\n\\nSimran Khanuja, Diksha Bansal, Sarvesh Mehtani,\\nSavya Khosla, Atreyee Dey, Balaji Gopalan,\\nDilip Kumar Margam, Pooja Aggarwal, Rajiv Teja\\n\\n\\x0cNagipogu, Shachi Dave, et al. 2021. Muril: Multi-\\nlingual representations for indian languages. arXiv\\npreprint arXiv:2103.10730.\\n\\nJoo-Kyung Kim, Young-Bum Kim, Ruhi Sarikaya, and\\nEric Fosler-Lussier. 2017. Cross-lingual transfer\\nlearning for pos tagging without cross-lingual re-\\nsources. In Proceedings of the 2017 conference on\\nempirical methods in natural language processing,\\npages 2832–2838.\\n\\nJan-Christoph Klie, Richard Eckart de Castilho, and\\nIryna Gurevych. 2023. Analyzing dataset annota-\\ntion quality management in the wild. arXiv preprint\\narXiv:2307.08153.\\n\\nAnoop Kunchukuttan, Pratik Mehta, and Pushpak Bhat-\\ntacharyya. 2018. The IIT Bombay English-Hindi\\nparallel corpus. In Proceedings of the Eleventh In-\\nternational Conference on Language Resources and\\nEvaluation (LREC 2018), Miyazaki, Japan. European\\nLanguage Resources Association (ELRA).\\n\\nYu-Hsiang Lin, Chian-Yu Chen, Jean Lee, Zirui Li,\\nYuyan Zhang, Mengzhou Xia, Shruti Rijhwani, Junx-\\nian He, Zhisong Zhang, Xuezhe Ma, et al. 2019.\\nChoosing transfer languages for cross-lingual learn-\\ning. arXiv preprint arXiv:1905.12688.\\n\\nBonan Min, Hayley Ross, Elior Sulem, Amir\\nPouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz,\\nEneko Agirre, Ilana Heintz, and Dan Roth. 2023.\\nRecent advances in natural language processing via\\nlarge pre-trained language models: A survey. ACM\\nComputing Surveys, 56(2):1–40.\\n\\nIndia (ORGI) Office of\\n\\nCensus Commissioner. 2022.\\ndia 2011 - LANGUAGE ATLAS -\\nhttps://censusindia.gov.in/nada/index.\\nphp/catalog/42561. [Accessed 05-06-2024].\\n\\nthe Registrar General\\nIn-\\nINDIA.\\n\\nCensus of\\n\\nAtul Kr. Ojha and Daniel Zeman. 2020. Universal\\ndependency treebanks for low-resource indian lan-\\nguages: The case of bhojpuri. In Proceedings of the\\nWILDRE5– 5th Workshop on Indian Language Data:\\nResources and Evaluation, pages 33–38, Marseille,\\nFrance. European Language Resources Association\\n(ELRA).\\n\\nJonas Pfeiffer, Ivan Vuli´c, Iryna Gurevych, and Se-\\nbastian Ruder. 2020. MAD-X: An Adapter-Based\\nFramework for Multi-Task Cross-Lingual Transfer.\\nIn Proceedings of the 2020 Conference on Empirical\\nMethods in Natural Language Processing (EMNLP),\\npages 7654–7673, Online. Association for Computa-\\ntional Linguistics.\\n\\nGowtham Ramesh, Sumanth Doddapaneni, Aravinth\\nBheemaraj, Mayank Jobanputra, Raghavan AK,\\nAjitesh Sharma, Sujit Sahoo, Harshita Diddee, Ma-\\nhalakshmi J, Divyanshu Kakwani, Navneet Kumar,\\nAswin Pradeep, Srihari Nagaraj, Kumar Deepak,\\nVivek Raghavan, Anoop Kunchukuttan, Pratyush Ku-\\nmar, and Mitesh Shantadevi Khapra. 2021. Samanan-\\ntar: The largest publicly available parallel corpora\\ncollection for 11 indic languages.\\n\\nNavanath Saharia, Dhrubajyoti Das, Utpal Sharma, and\\nJugal Kalita. 2009. Part of speech tagger for as-\\nIn Proceedings of the ACL-IJCNLP\\nsamese text.\\n2009 Conference Short Papers, pages 33–36.\\n\\nGuillaume Wenzek, Marie-Anne Lachaux, Alexis Con-\\nneau, Vishrav Chaudhary, Francisco Guzmán, Ar-\\nmand Joulin, and Edouard Grave. 2019. Ccnet: Ex-\\ntracting high quality monolingual datasets from web\\ncrawl data. arXiv preprint arXiv:1911.00359.\\n\\nA Appendix\\n\\nA.1 Extremely low resource languages\\n\\nAn extremely low-resource language has relatively\\nfew or no resources available. Compared to other\\nlanguages, Indian regional languages have lim-\\nited resources. These extremely low-resource lan-\\nguages are often considered less popular, poorly\\ndocumented, under-resourced, minority, or under-\\ndigitized due to their scarce resources. Much of the\\ndata and documentation for these languages remain\\nunpublished, exist only in print, or are extremely\\nlimited. Consequently, accessing and utilizing raw\\ntext in an extremely low-resource language is chal-\\nlenging.\\n\\nA.2 Language description\\n\\nTable 4 provides information on the languages of\\ninterest, including details such as scripts, number of\\nspeakers, data size, and geographical distributions.\\n\\nA.3 Languages and their characteristics\\n\\nOur primary languages of interest are Angika, Bho-\\njpuri, Hindi, and Magahi, spoken in the Indian\\nstates of Bihar, Jharkhand, West Bengal, and some\\nparts of Nepal. Table 4 provides an overview of\\nthe selected languages. These selected languages,\\nrepresenting the Bihari language group, belong\\nto the Indo-Aryan language family (Collin, 2010).\\nThey all use the Devanagari script, having transi-\\ntioned from their individual writing scripts. All\\nof these languages demonstrate tonal character-\\nistics. As far as morphosyntax is concerned, a\\nseparate morpheme marks the plural instead of\\na suffix. All the mentioned languages feature a\\nbound morpheme acting as a classifier. In addi-\\ntion to singular and plural forms, Angika, Magahi,\\nand Bhojpuri contain equal, honorific, and non-\\nhonorific variations of second-person personal pro-\\nnouns. Derived adjectives are present in all lan-\\nguages. While Angika and Bhojpuri offer all three\\ntenses, Bhojpuri lacks morphological availability\\nfor the present tense. Angika exhibits simple or\\n\\n\\x0cLanguage\\n\\nScripts\\n\\nAngika\\n\\nDevanagari\\n\\nNo. of\\nspeakers\\n15M\\n\\nNo. of\\nsentences\\n708\\n\\nGeographical\\ndistribution\\nBihar, Jharkhand, West Bengal,Nepal\\n\\nBhojpuri\\n\\nDevanagari\\n\\n52M\\n\\n708\\n\\nFiji, Bihar, Uttar Pradesh, Jharkhand,\\nChhattisgarh, Madhya Pradesh\\n\\nMagahi\\n\\nDevanagari\\n\\n14M\\n\\n708\\n\\nBihar, Jharkhand, Nepal\\n\\nTable 4: Data statistics showing language, writing script, number of native speakers, geographical distribution, and\\nnumber of sentences in our POS-tagging corpus across all four languages.\\n\\nwe opted for in-person discussions with annota-\\ntors to reach a consensus on correct annotations for\\neach word in the sentence. The manual, in-person\\napproaches to quality control are suitable and pro-\\nvide reassurance regarding the high quality of the\\nannotation (Cardenas et al., 2019). In cases of dis-\\nagreement, annotators collaborated with language\\nexperts to resolve the issue. For Hindi, sentence-\\nlevel annotation achieved over 90% agreement; for\\nAngika, Bhojpuri, and Magahi, sentence-level an-\\nnotation reached over 88% agreement. After qual-\\nity control, our corpus is the most extensive parallel\\ncorpus for Hindi, Angika, Bhojpuri, and Magahi\\nwithin the UD dataset, where test sets typically\\ninvolve 300 sentences.\\n\\nA.5 Experiment setup\\n\\nFor fine-tuning the PLMs, we employed a batch\\nsize of 16, a learning rate of 2e-5, and a weight\\ndecay of 0.01, and we conducted the experiments\\nover 10 epochs. The computations were performed\\nusing Nvidia A100 GPU.\\n\\ncontinuous tenses, and Magahi distinguishes be-\\ntween future and non-future tenses. The word order\\nfor all languages is Subject-Object-Verb (SOV).\\n\\nCloseness to Hindi Hindi, Angika, Bhojpuri, and\\nMagahi share similar word order (SOV) and scripts\\nand belong to the Indo-Aryan family. They dif-\\nfer significantly in number, gender, tense, aspect,\\nmood, and case markers. For example, Hindi verbs\\nundergo extensive conjugation for person, num-\\nber, tense, and mood. In contrast, Angika and Ma-\\ngahi verbs follow distinct conjugational patterns,\\nleading to variations in agreement and verb forms\\nwithin sentences. Furthermore, the structure and\\nplacement of relative clauses differ between the two\\nlanguages. Despite all languages utilizing the De-\\nvanagari script, identical words may convey differ-\\nent meanings. For example, consider the Hindi sen-\\ntence “hamen bachaav ke baare mein kuchh bhee\\nparavaah nahin thee” (We did not care about saving\\nanything), which translates to Angika as “hammae\\nsinee ka kuchchhoo bachaay ro baare mein par-\\navaay nai chelai.” Here, the pronoun \"hamen\" (we)\\nin Hindi is expressed in Angika as \"hammae si-\\nnee ka\" (we). While in Hindi, it represents the\\nfirst-person singular form, in Angika, it denotes the\\nfirst-person plural form.\\n\\nA.4 Quality control\\n\\nTo assess the quality of the POS annotation task,\\nwe abstained from computing automatic inter-\\nannotator agreement metrics like Fleiss Kappa\\n(Fleiss, 1971). For sequence labelling datasets,\\ndataset creators did not compute agreement as it\\nrelied on token level span (Klie et al., 2023). Brand-\\nsen et al. (2020) claims that per-token agreement\\nin sequence labelling presents challenges, as anno-\\ntators label sequences instead of individual tokens,\\ndiluting the measure’s ability to capture the essence\\nof the task. Additionally, nouns dominate the la-\\nbelled data, creating an imbalanced dataset that\\ncould skew results. Considering these challenges,\\n\\n\\x0cHindi Angika Magahi Bhojpuri AVG\\n0.73\\n0.74\\n0.89\\n0.90\\n0.94\\n0.96\\n0.45\\n0.51\\n0.95\\n0.81\\n0.84\\n0.96\\n0.82\\n0.87\\n0.93\\n0.49\\n0.48\\n0.78\\n\\n0.76\\n0.94\\n0.48\\n0.81\\n0.88\\n0.55\\n\\n0.68\\n0.82\\n0.36\\n0.78\\n0.70\\n0.43\\n\\n0.93\\n0.9\\n0.91\\n0.93\\n0.85\\n0.98\\n0.83\\n1.00\\n0.95\\n\\n0.83\\n0.75\\n0.47\\n0.69\\n0.5\\n0.99\\n0.63\\n1.00\\n0.71\\n\\n0.85\\n0.69\\n0.79\\n0.7\\n0.57\\n0.98\\n0.68\\n1.00\\n0.75\\n\\n0.87\\n0.74\\n0.75\\n0.63\\n0.49\\n1.00\\n0.63\\n1.00\\n0.82\\n\\n0.85\\n0.73\\n0.67\\n0.67\\n0.52\\n0.99\\n0.65\\n1.00\\n0.76\\n\\nTags\\nADJ\\nADP\\nADV\\nAUX\\nCCONJ\\nDET\\nINTJ\\nNOUN\\nNUM\\nPART\\nPRON\\nPROPN\\nPUNCT\\nSCONJ\\nSYM\\nVERB\\nX\\n-\\n\\nTable 5: F1-scores for POS tags across all languages. The average is calculated over Angika, Magahi, and Bhojpuri\\nonly. All scores are for MuRIL in the zero-shot setting, as it outperforms RemBERT and XLM-R-Large in this\\nscenario.\\n\\nHindi Angika Magahi Bhojpuri AVG\\n0.75\\n0.74\\n0.92\\n0.90\\n0.94\\n0.98\\n0.44\\n0.45\\n0.96\\n0.83\\n0.86\\n0.98\\n0.90\\n0.88\\n0.96\\n0.50\\n0.47\\n0.8\\n\\n0.78\\n0.94\\n0.48\\n0.84\\n0.89\\n0.59\\n\\n0.73\\n0.82\\n0.40\\n0.80\\n0.92\\n0.44\\n\\n0.87\\n0.76\\n0.47\\n0.76\\n0.64\\n0.99\\n0.53\\n1.00\\n0.78\\n\\n0.86\\n0.68\\n0.76\\n0.8\\n0.65\\n1.00\\n0.71\\n1.00\\n0.81\\n\\n0.89\\n0.69\\n0.72\\n0.76\\n0.61\\n1.00\\n0.70\\n1.00\\n0.86\\n\\n0.87\\n0.71\\n0.65\\n0.77\\n0.63\\n1.00\\n0.65\\n1.00\\n0.80\\n\\nTags\\nADJ\\nADP\\nADV\\nAUX\\nCCONJ\\nDET\\nINTJ\\n0.96\\nNOUN\\n0.91\\nNUM\\n0.90\\nPART\\nPRON\\n0.96\\nPROPN 0.88\\n0.99\\nPUNCT\\n0.85\\nSCONJ\\n1.00\\nSYM\\n0.97\\nVERB\\nX\\n-\\n\\nTable 6: F1-scores for POS tags across all languages. The average is calculated over Angika, Magahi, and Bhojpuri\\nonly. All scores are for MuRIL in the look-back setting.\\n\\n\\x0cHindi Angika Magahi Bhojpuri AVG\\n0.74\\n0.74\\n0.95\\n0.90\\n0.94\\n0.98\\n0.44\\n0.49\\n0.95\\n0.81\\n0.84\\n0.98\\n0.88\\n0.87\\n0.97\\n0.52\\n0.58\\n0.81\\n\\n0.76\\n0.94\\n0.48\\n0.82\\n0.88\\n0.55\\n\\n0.73\\n0.82\\n0.36\\n0.78\\n0.89\\n0.43\\n\\n0.83\\n0.75\\n0.44\\n0.78\\n0.64\\n0.99\\n0.63\\n1.00\\n0.74\\n\\n0.85\\n0.69\\n0.79\\n0.7\\n0.57\\n0.98\\n0.68\\n1.00\\n0.75\\n\\n0.87\\n0.82\\n0.74\\n0.75\\n0.59\\n1.00\\n0.63\\n1.00\\n0.82\\n\\n0.85\\n0.75\\n0.66\\n0.74\\n0.60\\n0.99\\n0.65\\n1.00\\n0.76\\n\\nTags\\nADJ\\nADP\\nADV\\nAUX\\nCCONJ\\nDET\\nINTJ\\nNOUN\\n0.95\\nNUM\\n0.92\\nPART\\n0.88\\n0.96\\nPRON\\nPROPN 0.87\\n0.98\\nPUNCT\\n0.83\\nSCONJ\\n1.00\\nSYM\\nVERB\\n0.97\\nX\\n-\\n\\nTable 7: F1-scores for POS tags across all languages. The average is calculated over Angika, Magahi, and Bhojpuri\\nonly. All scores are for MuRIL in the look-back-with-score setting.\\n\\n\\x0c')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(pdf_content), len(pdf_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMRTVncmM8Y1",
        "outputId": "8cfe932e-6247-475a-b7ca-5f66fb58d6c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Note that:** Here, It is not extracted page wise.\n",
        "\n",
        "- **Note2 that:** Text is stored in **document object**. A Document object is a generic class for storing a piece of unstructured text and its associated metadata"
      ],
      "metadata": {
        "id": "nzSsnbyuNET6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Split the text into smaller chunks\n",
        "\n",
        "There are several different text splitters.\n",
        "\n",
        "<br>\n",
        "\n",
        "Two common ones are:\n",
        "\n",
        "\n",
        "**CharacterTextSplitter:** Split text based on a certain number characters.\n",
        "\n",
        "**TokenTextSplitter:** Split text to tokens using model tokenizer."
      ],
      "metadata": {
        "id": "BGfQ71TTPOYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter\n",
        "\n",
        "CHUNK_SIZE = 2000\n",
        "CHUNK_OVERLAP = 200\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size = CHUNK_SIZE, chunk_overlap = CHUNK_OVERLAP)\n",
        "docs = text_splitter.split_documents(pdf_content)"
      ],
      "metadata": {
        "id": "XzDe3fBYPVWK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6K14FNVPN7a",
        "outputId": "a5ed572b-dc05-4a9d-a2cf-0560060c3750"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/paper-1.pdf'}, page_content='Part-of-speech Tagging for Extremely Low-resource Indian Languages\\n\\nSanjeev Kumar, Preethi Jyothi, Pushpak Bhattacharyya\\nComputer Science and Engineering, IIT Bombay, India\\n{sanjeev, pjyothi, pb}@cse.iitb.ac.in\\n\\nAbstract\\n\\nModern natural language processing (NLP) sys-\\ntems thrive when given access to large datasets.\\nHowever, a large fraction of the world’s lan-\\nguages are not privy to such benefits due to\\nsparse documentation and inadequate digital\\nrepresentation. This is especially true for In-\\ndian regional languages. As a first step towards\\nexpanding the reach of NLP technologies to\\nextremely low-resource Indian languages, we\\npresent a new parallel part-of-speech (POS)\\nevaluation dataset for Angika, Magahi, Bho-\\njpuri and Hindi. Angika, Magahi, Bhojpuri,\\nalong with the more well-known Hindi, are all\\nlanguages spoken in the Indian states of Bi-\\nhar, Jharkhand and West Bengal. Ours is no-\\ntably the first NLP resource, even for a shallow\\nNLP task like POS-tagging, for Angika. We\\nestablish POS-tagging baselines using state-of-\\nthe-art multilingual pretrained language models\\n(PLMs) finetuned on Hindi data, and show zero-\\nshot evaluations on the other three languages.\\nWhile all four languages use the same Devana-\\ngari script, pretrained tokenizers underperform\\nin zero-shot on the three languages. We pro-\\npose a simple look-back fix to address the tok-\\nenization challenge yielding F1-score improve-\\nments of up to 8% on Angika, and show how\\nit comes very close to an oracle setting when\\nthe underlying Hindi word is known (and can\\nbe accurately tokenized).\\n\\n1\\n\\nIntroduction')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HbElRGpNCSj",
        "outputId": "f02149d3-3089-42d1-a44a-42dbf8b02e33"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Embed and store the documents in the vector database\n",
        "\n",
        "In this step, we convert text chunks into embedding vectors using models from OpenAI, Hugging Face, Cohere, or a custom model. Model selection depends on:\n",
        "\n",
        "- **Cost**: Using providers like OpenAI or Cohere can become costly at scale.\n",
        "- **Latency and Speed**: Hosting a model reduces latency; using an API increases it.\n",
        "- **Convenience**: Custom models require more resources and maintenance, while vendor APIs offer ease of use.\n"
      ],
      "metadata": {
        "id": "FbYVv-7aQldj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai qdrant-client -q"
      ],
      "metadata": {
        "id": "ne1qGCUZNHCq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Qdrant"
      ],
      "metadata": {
        "id": "CDkxIN9PR17Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"YOUR-API-KEY\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "g7xK2E33RdbG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(model = 'text-embedding-ada-002')\n",
        "\n",
        "\n",
        "q_drant = Qdrant.from_documents(docs,\n",
        "                                embeddings,\n",
        "                                path = '\\tmp\\local_qdrant',\n",
        "                                collection_name = 'my_documents',\n",
        "                                force_recreate = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNiQykf5SZgv",
        "outputId": "4bb8af1d-6aef-48e3-8386-acf12c170212"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-61146dfa453c>:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings(model = 'text-embedding-ada-002')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are tokenization inconsistency?\"\n",
        "\n",
        "found_docs = q_drant.similarity_search(query)\n",
        "\n",
        "found_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFHNxHL7Uqfz",
        "outputId": "e4dfabc2-f3e7-4a0e-f1ae-fbc555638421"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/paper-1.pdf', '_id': 'ecdff49529d942de9f02218e5644486e', '_collection_name': 'my_documents'}, page_content='4.2 Tokenization Inconsistencies\\n\\nIn the case of extremely low-resource languages,\\na pretrained tokenizer tends to break words into\\nmultiple sub-word tokens. In our experiments, we\\npredict POS tags for each token. Thus, sub-optimal\\ntokenization can result in poor quality predictions.\\nFor extremely low-resource languages, words may\\nbe split all the way down into individual characters\\nwhich makes the POS predictions even noisier. In\\nSection 4.3, we propose a simple look-back scheme\\nto alleviate some of the issues that stem from poor\\ntokenization. In Section 4.4, we analyze how much\\nwe could make up for tokenization challenges in\\nan oracle setting if we had access to parallel data\\nin Hindi.\\n\\n4.3\\n\\nInvestigating the impact of sub-word\\n\\nWhen a tokenizer breaks down words into sub-\\nwords, these sub-words can get different tags. Poor\\ntokenization that leads to over-fragmentation ex-\\nacerbates this problem. In our quantitative dataset\\nanalysis, we observed that in Angika, Magahi and\\nBhojpuri around 45% of words were split into 2, 3,\\nand 4 sub-word tokens. To address this challenge,\\nwe introduce two simple techniques: look-back and\\nlook-back-with-score.\\n\\nLook-back. We substitute the POS tags corre-\\nsponding to all the tokens in a word with the POS\\ntag of the first token. This approach was chosen\\nbecause the first split token closely relates to the\\nword in a higher-resource language, preserving\\nmeaning and POS tags. For example, an Angika\\nword “dEkhAibae\" (will see), splits into “dEkh”\\nand “ibae” here, the word “dEkh” (see) is related\\nto Hindi. The results of this look-back approach\\n\\nare shown in Table 1. We find significant improve-\\nments in performance across all three low-resource\\nlanguages, most notably for Angika.\\n\\nIf a word W is split'),\n",
              " Document(metadata={'source': '/content/paper-1.pdf', '_id': '37bd9fa5a1ee449bbeab2b1b84ee0bc7', '_collection_name': 'my_documents'}, page_content='1https://www.github.com/snjev310/acl-24-pos\\n\\n\\x0cand Cohn (2016) achieve successful POS tagging,\\nespecially in low-resource languages (like Mala-\\ngasy and Kinyarwanda), by combining word align-\\nment with gold-standard data. Kim et al. (2017) im-\\nplemented a BiLSTM model that utilizes word and\\ncharacter embeddings to transfer knowledge with-\\nout relying on parallel corpora. Another approach\\nby Huck et al. (2019) introduces zero-shot tag-\\nging, by projecting annotations from a related high-\\nresource language, such as Russian for Ukrainian.\\nMore recently, Dione et al. (2023) demonstrated\\nsignificant improvements in POS tagging by using\\nmultilingual pretrained LMs trained on typologi-\\ncally diverse African languages. Recent work has\\nalso employed modular learning (Lin et al., 2019;\\nArtetxe et al., 2020; Pfeiffer et al., 2020; Min et al.,\\n2023) techniques with multilingual pretrained lan-\\nguage models (PLMs) to enable effective cross-\\nlingual transfer to low-resource languages. Prior\\nwork on POS tagging for various low-resource\\nIndo-Aryan languages has mainly utilized classical\\nNLP techniques and do not leverage PLMs. For\\nexample, Saharia et al. (2009) developed a POS\\ntagger for Assamese and Basit and Kumar (2019)\\nfor Awadhi, and both works used an HMM model.\\nAmong the four languages of interest, other than\\nHindi, there is an existing UD-compliant POS-\\ntagging evaluation dataset for Bhojpuri (Ojha and\\nZeman, 2020). However, it only has 268 sentences.\\nOverall, there is a strong need for NLP datasets\\ncovering extremely low-resource Indian languages\\n(such as Angika). We think it is also useful to de-\\nvelop parallel datasets along with relatively higher-\\nresource languages (such as Hindi) that share com-\\nmon geographical boundaries, word order, script,\\nand language family. This helps understand how\\ncross-lingual transfer can be more effectively uti-\\nlized from high-resource languages.\\n\\n3 Data Collection and Annotation'),\n",
              " Document(metadata={'source': '/content/paper-1.pdf', '_id': 'cd8bfbdb030a4627a82d078cccc5c121', '_collection_name': 'my_documents'}, page_content='continuous tenses, and Magahi distinguishes be-\\ntween future and non-future tenses. The word order\\nfor all languages is Subject-Object-Verb (SOV).\\n\\nCloseness to Hindi Hindi, Angika, Bhojpuri, and\\nMagahi share similar word order (SOV) and scripts\\nand belong to the Indo-Aryan family. They dif-\\nfer significantly in number, gender, tense, aspect,\\nmood, and case markers. For example, Hindi verbs\\nundergo extensive conjugation for person, num-\\nber, tense, and mood. In contrast, Angika and Ma-\\ngahi verbs follow distinct conjugational patterns,\\nleading to variations in agreement and verb forms\\nwithin sentences. Furthermore, the structure and\\nplacement of relative clauses differ between the two\\nlanguages. Despite all languages utilizing the De-\\nvanagari script, identical words may convey differ-\\nent meanings. For example, consider the Hindi sen-\\ntence “hamen bachaav ke baare mein kuchh bhee\\nparavaah nahin thee” (We did not care about saving\\nanything), which translates to Angika as “hammae\\nsinee ka kuchchhoo bachaay ro baare mein par-\\navaay nai chelai.” Here, the pronoun \"hamen\" (we)\\nin Hindi is expressed in Angika as \"hammae si-\\nnee ka\" (we). While in Hindi, it represents the\\nfirst-person singular form, in Angika, it denotes the\\nfirst-person plural form.\\n\\nA.4 Quality control\\n\\nTo assess the quality of the POS annotation task,\\nwe abstained from computing automatic inter-\\nannotator agreement metrics like Fleiss Kappa\\n(Fleiss, 1971). For sequence labelling datasets,\\ndataset creators did not compute agreement as it\\nrelied on token level span (Klie et al., 2023). Brand-\\nsen et al. (2020) claims that per-token agreement\\nin sequence labelling presents challenges, as anno-\\ntators label sequences instead of individual tokens,\\ndiluting the measure’s ability to capture the essence\\nof the task. Additionally, nouns dominate the la-\\nbelled data, creating an imbalanced dataset that\\ncould skew results. Considering these challenges,'),\n",
              " Document(metadata={'source': '/content/paper-1.pdf', '_id': '6a92f6e06e284693b77e1e3f40523762', '_collection_name': 'my_documents'}, page_content='Non-oracle setting. We substitute the predicted\\ntags of a token with the original tags from the par-\\nallel corpus. This involves choosing the tag with\\nthe highest frequency for an aligned Hindi token in\\nthe parallel corpus. In this setting, we achieve F1-\\nscores of 0.67, 0.63, and 0.65 for Angika, Magahi,\\nand Bhojpuri, respectively, which is significantly\\nlower than the scores obtained in the zero-shot and\\noracle settings.\\n\\nTable 2 presents the results of both approaches.\\nWhen comparing the oracle and non-oracle results\\nwith the zero-shot approach, we observe that hav-\\ning access to a parallel corpus in a comparatively\\nhigher-resource language improves the overall tag-\\nging performance, primarily when focusing on\\nwrongly predicted tags. However, since we do not\\nhave apriori information of whether our predicted\\ntag is correct or not, the non-oracle approach of\\nalways replacing it with the Hindi token’s most\\n\\nfrequent POS tag results in a notable decline in\\nperformance.\\n\\n4.5 Tag-level Analysis')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(found_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgPKAJ3EVHm3",
        "outputId": "98d21cc5-dee2-4f95-e5e2-327363fb52dc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "found_docs[1].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "_XvOWkeTXSt6",
        "outputId": "1c0a0866-b494-4549-e2de-39e0089299ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1https://www.github.com/snjev310/acl-24-pos\\n\\n\\x0cand Cohn (2016) achieve successful POS tagging,\\nespecially in low-resource languages (like Mala-\\ngasy and Kinyarwanda), by combining word align-\\nment with gold-standard data. Kim et al. (2017) im-\\nplemented a BiLSTM model that utilizes word and\\ncharacter embeddings to transfer knowledge with-\\nout relying on parallel corpora. Another approach\\nby Huck et al. (2019) introduces zero-shot tag-\\nging, by projecting annotations from a related high-\\nresource language, such as Russian for Ukrainian.\\nMore recently, Dione et al. (2023) demonstrated\\nsignificant improvements in POS tagging by using\\nmultilingual pretrained LMs trained on typologi-\\ncally diverse African languages. Recent work has\\nalso employed modular learning (Lin et al., 2019;\\nArtetxe et al., 2020; Pfeiffer et al., 2020; Min et al.,\\n2023) techniques with multilingual pretrained lan-\\nguage models (PLMs) to enable effective cross-\\nlingual transfer to low-resource languages. Prior\\nwork on POS tagging for various low-resource\\nIndo-Aryan languages has mainly utilized classical\\nNLP techniques and do not leverage PLMs. For\\nexample, Saharia et al. (2009) developed a POS\\ntagger for Assamese and Basit and Kumar (2019)\\nfor Awadhi, and both works used an HMM model.\\nAmong the four languages of interest, other than\\nHindi, there is an existing UD-compliant POS-\\ntagging evaluation dataset for Bhojpuri (Ojha and\\nZeman, 2020). However, it only has 268 sentences.\\nOverall, there is a strong need for NLP datasets\\ncovering extremely low-resource Indian languages\\n(such as Angika). We think it is also useful to de-\\nvelop parallel datasets along with relatively higher-\\nresource languages (such as Hindi) that share com-\\nmon geographical boundaries, word order, script,\\nand language family. This helps understand how\\ncross-lingual transfer can be more effectively uti-\\nlized from high-resource languages.\\n\\n3 Data Collection and Annotation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation Component Implementation\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "E9jdGIUdXyzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{The steps for generating a response for a user’s question are:}$\n",
        "\n",
        "**Step 1:** Embed the user’s query using the same model used for embedding documents\n",
        "\n",
        "**Step 2:** Pass the query embedding to vector database, search and retrieve the top-k documents (i.e. context) from the vector database\n",
        "\n",
        "**Step 3:** Create a “prompt” and include the user’s query and context in it\n",
        "\n",
        "**Step 4:** Call the LLM and pass the the prompt\n",
        "\n",
        "**Step 5:** Get the generated response from LLM and display it to the user"
      ],
      "metadata": {
        "id": "XkqSTXZKYbZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## load_qa_chain\n",
        "\n",
        "`load_qa_chain()` is a function in Langchain that loads a pre-configured question-answering chain. It uses a language model like OpenAI and allows you to choose how to extract answers.\n",
        "\n",
        "$\\text{Note:}$ You can also add a prompt template and memory if you want. The function gives you a `QuestionAnsweringChain` that can take documents and questions to generate answers.\n"
      ],
      "metadata": {
        "id": "HGRDB6xz3P0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "xvtbONwO4VgD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "d6mj936p3l2a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm=OpenAI(), chain_type='stuff')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_65SkjX3PVC",
        "outputId": "80f38901-54cf-4245-862b-2479d00be8e1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-01856a8e0379>:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  chain = load_qa_chain(llm=OpenAI(), chain_type='stuff')\n",
            "<ipython-input-24-01856a8e0379>:1: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
            "stuff: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain\n",
            "map_reduce: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_reduce_chain\n",
            "refine: https://python.langchain.com/v0.2/docs/versions/migrating_chains/refine_chain\n",
            "map_rerank: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_rerank_docs_chain\n",
            "\n",
            "See also guides on retrieval and question-answering here: https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag\n",
            "  chain = load_qa_chain(llm=OpenAI(), chain_type='stuff')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What is tokenization inconsistency?'"
      ],
      "metadata": {
        "id": "Lx0zCNS3XyU_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "found_docs = q_drant.similarity_search(query)\n",
        "\n",
        "answer = chain.run(input_documents = found_docs, question = query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s85iXO2QXXcQ",
        "outputId": "0f0aedca-0286-4e6e-8a4c-cbe4d158e184"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-7e9b4cb4c5ea>:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  answer = chain.run(input_documents = found_docs, question = query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tokenization inconsistency refers to the issue of a tokenizer breaking words into multiple sub-word tokens in extremely low-resource languages, resulting in poor quality predictions for POS tagging. This can be addressed through techniques such as look-back and look-back-with-score. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load_qa_with_sources_chain()\n",
        "\n",
        "This is very similar to `load_qa_chain` except it contains sources/metadata along with the returned response."
      ],
      "metadata": {
        "id": "jYk3fekY5SwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "\n",
        "\n",
        "chain = load_qa_with_sources_chain(llm = OpenAI(), chain_type = 'stuff')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LKogOer4wlK",
        "outputId": "7283f1d2-7af1-4a81-c1bc-bf7b841b5410"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-7f9b5870f16e>:4: LangChainDeprecationWarning: This function is deprecated. Refer to this guide on retrieval and question answering with sources: https://python.langchain.com/v0.2/docs/how_to/qa_sources/\n",
            "See also the following migration guides for replacements based on `chain_type`:\n",
            "stuff: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain\n",
            "map_reduce: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_reduce_chain\n",
            "refine: https://python.langchain.com/v0.2/docs/versions/migrating_chains/refine_chain\n",
            "map_rerank: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_rerank_docs_chain\n",
            "\n",
            "  chain = load_qa_with_sources_chain(llm = OpenAI(), chain_type = 'stuff')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What is tokenization inconsistency?'"
      ],
      "metadata": {
        "id": "g3L9R4jD50KN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chain({'input_documents': found_docs, 'question':query}, return_only_outputs=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5cJ_6XH5tN-",
        "outputId": "d127577f-9deb-49e7-eece-3b6001dd6953"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-8ea7e6327664>:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  answer = chain({'input_documents': found_docs, 'question':query}, return_only_outputs=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer['output_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnOU-ls56KHC",
        "outputId": "7c71bcb6-c2c0-40f0-b471-55c933f3720b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tokenization inconsistency is a problem that arises in extremely low-resource languages when a pretrained tokenizer breaks words into multiple sub-word tokens, resulting in poor quality predictions for POS tags. To address this issue, a look-back approach is used, where the POS tags of all tokens in a word are substituted with the POS tag of the first token. This approach has shown significant improvements in performance for low-resource languages such as Angika. Other techniques, such as using a parallel corpus, have also been explored to improve POS tagging in these languages. However, there is a need for more NLP datasets covering extremely low-resource Indian languages and for developing parallel datasets with relatively higher-resource languages to better utilize cross-lingual transfer. SOURCES: /content/paper-1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RetrievalQA()\n",
        "\n",
        "`RetrievalQA` is a class in Langchain that creates a question answering chain using retrieval. It combines a retriever, prompt template, and LLM together into an end-to-end QA pipeline. The prompt template formats the question and retrieved documents into a prompt for the LLM. This chain retrieves relevant documents from a vector database for a given query, and then generates an answer using those documents."
      ],
      "metadata": {
        "id": "egF1O74o6hg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import  load_qa_chain\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "kwVAW7Ab6g6j"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm=OpenAI(temperature=0), chain_type='stuff')\n",
        "\n",
        "answer = chain.run(input_documents = found_docs, question = query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8PECErS6P8h",
        "outputId": "738eb307-48c0-465a-e847-d243e6778dad"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tokenization inconsistency refers to the issue of a tokenizer breaking words into multiple sub-word tokens, which can result in poor quality predictions for tasks such as POS tagging. This can be particularly problematic for extremely low-resource languages, where words may be split into individual characters, making the predictions even noisier.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm=OpenAI(temperature=0.5), chain_type='stuff')\n",
        "\n",
        "answer = chain.run(input_documents = found_docs, question = query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd60fFWF7Jg7",
        "outputId": "68456173-ef9b-43af-ab2c-835354b3c466"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tokenization inconsistency refers to the issue of a pretrained tokenizer breaking words into multiple sub-word tokens, which can result in poor quality predictions for POS tagging tasks.\n"
          ]
        }
      ]
    }
  ]
}